{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50 #, preprocess_inputcond\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "import pandas as pd\n",
    "#from data import *\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 256, 256\n",
    "NB_EPOCHS = 3\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataProcess(object):\n",
    "\n",
    "    def __init__(self, out_rows, out_cols, image_path=\"../data/image/\", train1_path = \"/train/A\", train2_path = \"/train/P1B\", test1_path = \"/test/A\",test2_path = \"/test/P1B\", npy_path = \"../npy/\", img_type = \"jpg\"):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.image_path = image_path\n",
    "        self.train1_path = train1_path\n",
    "        self.train2_path = train2_path\n",
    "        self.img_type = img_type\n",
    "        self.test1_path = test1_path\n",
    "        self.test2_path = test2_path\n",
    "        self.npy_path = npy_path\n",
    "\n",
    "    def create_train_data(self, index):\n",
    "        npy_folder_path = self.npy_path+'%s'%str(index)\n",
    "\n",
    "        i = 0\n",
    "        print('-'*30)\n",
    "        print('Creating training images...')\n",
    "        print('-'*30)\n",
    "        train1_folder_path = self.image_path+'%s'%str(index)+ self.train1_path\n",
    "        imgs1 = glob.glob(train1_folder_path+\"/*.\"+self.img_type)\n",
    "        print(train1_folder_path)\n",
    "        print(len(imgs1))\n",
    "\n",
    "\n",
    "        imgdatas1 = np.ndarray((len(imgs1),self.out_rows,self.out_cols,3), dtype=np.uint8)\n",
    "        imglabels1 = np.ndarray((len(imgs1),1), dtype=np.uint8)\n",
    "        for imgname in imgs1:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "\n",
    "            img = load_img(train1_folder_path + \"/\" + midname)\n",
    "            img=img.resize((256,256))\n",
    "            img = img_to_array(img)\n",
    "            imgdatas1[i] = img\n",
    "            imglabels1[i] = 0\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(imgs1)))\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "\n",
    "        np.save(npy_folder_path + '/train1_256.npy', imgdatas1)\n",
    "        np.save(npy_folder_path + '/label1_256.npy', imglabels1)\n",
    "        print('Saving to .npy files done. (1)')\n",
    "\n",
    "        i = 0\n",
    "        train2_folder_path = self.image_path+'%s'%str(index)+ self.train2_path\n",
    "        imgs2 = glob.glob(train2_folder_path+\"/*.\"+self.img_type)\n",
    "        print(len(imgs2))\n",
    "        imgdatas2 = np.ndarray((len(imgs2),self.out_rows,self.out_cols,3), dtype=np.uint8)\n",
    "        imglabels2 = np.ndarray((len(imgs2),1), dtype=np.uint8)\n",
    "        for imgname in imgs2:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "\n",
    "            img2 = load_img(train2_folder_path + \"/\" + midname)\n",
    "            img2=img2.resize((256,256))\n",
    "            img2 = img_to_array(img2)\n",
    "            imgdatas2[i] = img2\n",
    "            imglabels2[i] = 1\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(imgs2)))\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(npy_folder_path + '/train2_256.npy', imgdatas2)\n",
    "        np.save(npy_folder_path + '/label2_256.npy', imglabels2)\n",
    "        print('Saving to .npy files done. (2)')\n",
    "\n",
    "    def create_test_data(self, index):\n",
    "        npy_folder_path = self.npy_path+'%s'%str(index)\n",
    "        i = 0\n",
    "        print('-'*30)\n",
    "        print('Creating test images...')\n",
    "        print('-'*30)\n",
    "\n",
    "        test1_folder_path = self.image_path+'%s'%str(index)+ self.test1_path\n",
    "        test2_folder_path = self.image_path+'%s'%str(index)+ self.test2_path\n",
    "        imgs1 = glob.glob(test1_folder_path+\"/*.\"+self.img_type)\n",
    "        imgs2 = glob.glob(test2_folder_path+\"/*.\"+self.img_type)\n",
    "        print(len(imgs1))\n",
    "        print(len(imgs2))\n",
    "\n",
    "        imgdatas1 = np.ndarray((len(imgs1),self.out_rows,self.out_cols,3), dtype=np.uint8)\n",
    "        imglabels1 = np.ndarray((len(imgs1),1), dtype=np.uint8)\n",
    "        for imgname in imgs1:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(test1_folder_path + \"/\" + midname)\t\n",
    "            img=img.resize((256,256))\n",
    "            img = img_to_array(img)\n",
    "            imgdatas1[i] = img\n",
    "            imglabels1[i] = 0\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(npy_folder_path + '/test1_256.npy', imgdatas1)\n",
    "        np.save(npy_folder_path + '/test_label1_256.npy', imglabels1)\n",
    "        print('Saving to imgs_test.npy files done.(1)')\n",
    "\n",
    "        i = 0\n",
    "        imgdatas2 = np.ndarray((len(imgs2),self.out_rows,self.out_cols,3), dtype=np.uint8)\n",
    "        imglabels2 = np.ndarray((len(imgs2),1), dtype=np.uint8)\n",
    "        for imgname in imgs2:\n",
    "            midname = imgname[imgname.rindex(\"/\")+1:]\n",
    "            img = load_img(test2_folder_path + \"/\" + midname)\t\n",
    "            img=img.resize((256,256))\n",
    "            img = img_to_array(img)\n",
    "            imgdatas2[i] = img\n",
    "            imglabels2[i] = 1\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(npy_folder_path + '/test2_256.npy', imgdatas2)\n",
    "        np.save(npy_folder_path + '/test_label2_256.npy', imglabels2)\n",
    "        print('Saving to imgs_test.npy files done.(1)')\n",
    "\n",
    "\n",
    "    def load_train_data(self, index):\n",
    "        npy_folder_path = self.npy_path+'%s'%str(index)\n",
    "        print(npy_folder_path)\n",
    "        \n",
    "        print('-'*30)\n",
    "        print('load train images...')\n",
    "        print('-'*30)\n",
    "        \n",
    "        imgs_train1 = np.load(npy_folder_path+\"/train1_256.npy\")\n",
    "        imgs_mask_train1 = np.load(npy_folder_path+\"/label1_256.npy\")\n",
    "        imgs_train1 = imgs_train1.astype('float32')/255\n",
    "\n",
    "        imgs_train2 = np.load(npy_folder_path+\"/train2_256.npy\")\n",
    "        imgs_mask_train2 = np.load(npy_folder_path+\"/label2_256.npy\")  \n",
    "        imgs_train2 = imgs_train2.astype('float32')/255\n",
    "        \n",
    "        imgs_train=np.append(imgs_train1,imgs_train2,axis=0)\n",
    "        imgs_mask_train=np.append(imgs_mask_train1,imgs_mask_train2,axis=0)\n",
    "        print(imgs_train.shape)\n",
    "        print(imgs_mask_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "        return imgs_train,imgs_mask_train\n",
    "\n",
    "    def load_test_data(self, index):\n",
    "        npy_folder_path = self.npy_path+'%s'%str(index)\n",
    "        print(npy_folder_path)\n",
    "        \n",
    "        print('-'*30)\n",
    "        print('load test images...')\n",
    "        print('-'*30)\n",
    "        imgs_test1 = np.load(npy_folder_path+\"/test1_256.npy\")\n",
    "        imgs_mask_test1 = np.load(npy_folder_path+\"/test_label1_256.npy\")\n",
    "        imgs_test1 = imgs_test1.astype('float32')/255\n",
    "\n",
    "        imgs_test2 = np.load(npy_folder_path+\"/test2_256.npy\")\n",
    "        imgs_mask_test2 = np.load(npy_folder_path+\"/test_label2_256.npy\")\n",
    "        imgs_test2 = imgs_test2.astype('float32')/255\n",
    "        \n",
    "        imgs_test=np.append(imgs_test1,imgs_test2,axis=0)\n",
    "        imgs_mask_test=np.append(imgs_mask_test1,imgs_mask_test2,axis=0)\n",
    "        print(imgs_test.shape)\n",
    "        print(imgs_mask_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "        return imgs_test,imgs_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, test data\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    mydata = dataProcess(256,256)\n",
    "    mydata.create_train_data(0)\n",
    "    mydata.create_train_data(1)\n",
    "    mydata.create_train_data(2)\n",
    "    mydata.create_train_data(3)\n",
    "    mydata.create_train_data(4)\n",
    "\n",
    "    mydata.create_test_data(0)\n",
    "    mydata.create_test_data(1)\n",
    "    mydata.create_test_data(2)\n",
    "    mydata.create_test_data(3)\n",
    "    mydata.create_test_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../npy/1\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "(732, 256, 256, 3)\n",
      "(732, 1)\n",
      "../npy/1\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(183, 256, 256, 3)\n",
      "(183, 1)\n",
      "(732, 1)\n",
      "(183, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/younji/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/ubuntu/.conda/envs/younji/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 2 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 2 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 2 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 5 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 5 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 5 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 5 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 1 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 1 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 1 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 2 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 2 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            4098        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/300\n",
      "585/585 [==============================] - 19s 33ms/step - loss: 0.7970 - accuracy: 0.6940 - val_loss: 3.6465 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.64653, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 2/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.3068 - accuracy: 0.8701 - val_loss: 4.4179 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.64653\n",
      "Epoch 3/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1401 - accuracy: 0.9556 - val_loss: 3.0331 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.64653 to 3.03307, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 4/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1007 - accuracy: 0.9709 - val_loss: 2.4396 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.03307 to 2.43955, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 5/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0692 - accuracy: 0.9812 - val_loss: 3.1997 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.43955\n",
      "Epoch 6/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0949 - accuracy: 0.9761 - val_loss: 4.7078 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.43955\n",
      "Epoch 7/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1103 - accuracy: 0.9624 - val_loss: 5.7489 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.43955\n",
      "Epoch 8/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0926 - accuracy: 0.9573 - val_loss: 7.5618 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.43955\n",
      "Epoch 9/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0781 - accuracy: 0.9744 - val_loss: 5.8663 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.43955\n",
      "Epoch 10/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1202 - accuracy: 0.9692 - val_loss: 6.2036 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.43955\n",
      "Epoch 11/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 6.7582 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.43955\n",
      "Epoch 12/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 7.8978 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.43955\n",
      "Epoch 13/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 5.9260 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.43955\n",
      "Epoch 14/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0400 - accuracy: 0.9897 - val_loss: 5.9350 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.43955\n",
      "Epoch 15/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0426 - accuracy: 0.9846 - val_loss: 8.0893 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.43955\n",
      "Epoch 16/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0409 - accuracy: 0.9846 - val_loss: 9.5551 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.43955\n",
      "Epoch 17/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 7.9762 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.43955\n",
      "Epoch 18/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 7.5897 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.43955\n",
      "Epoch 19/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0243 - accuracy: 0.9897 - val_loss: 7.5169 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.43955\n",
      "Epoch 20/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0464 - accuracy: 0.9812 - val_loss: 7.6537 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.43955\n",
      "Epoch 21/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 8.4419 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.43955\n",
      "Epoch 22/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 9.8695 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.43955\n",
      "Epoch 23/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 7.5035 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.43955\n",
      "Epoch 24/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0483 - accuracy: 0.9846 - val_loss: 6.3429 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.43955\n",
      "Epoch 25/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 6.6854 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.43955\n",
      "Epoch 26/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0085 - accuracy: 0.9966 - val_loss: 7.0735 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.43955\n",
      "Epoch 27/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 6.9754 - val_accuracy: 0.0136\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.43955\n",
      "Epoch 28/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0818 - accuracy: 0.9709 - val_loss: 8.5297 - val_accuracy: 0.0612\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.43955\n",
      "Epoch 29/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1246 - accuracy: 0.9487 - val_loss: 1.8764 - val_accuracy: 0.4490\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.43955 to 1.87641, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 30/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0901 - accuracy: 0.9761 - val_loss: 3.3462 - val_accuracy: 0.3605\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.87641\n",
      "Epoch 31/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1679 - accuracy: 0.9641 - val_loss: 6.3238 - val_accuracy: 0.1156\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.87641\n",
      "Epoch 32/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0865 - accuracy: 0.9726 - val_loss: 7.5815 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.87641\n",
      "Epoch 33/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1248 - accuracy: 0.9521 - val_loss: 7.2627 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.87641\n",
      "Epoch 34/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0862 - accuracy: 0.9658 - val_loss: 4.2523 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.87641\n",
      "Epoch 35/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.9897 - val_loss: 4.0030 - val_accuracy: 0.2993\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.87641\n",
      "Epoch 36/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0187 - accuracy: 0.9915 - val_loss: 4.2310 - val_accuracy: 0.3537\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.87641\n",
      "Epoch 37/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 5.1727 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.87641\n",
      "Epoch 38/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0111 - accuracy: 0.9949 - val_loss: 4.3452 - val_accuracy: 0.3605\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.87641\n",
      "Epoch 39/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.1101 - val_accuracy: 0.4014\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.87641\n",
      "Epoch 40/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.4433 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.87641\n",
      "Epoch 41/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7768 - val_accuracy: 0.4014\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.87641\n",
      "Epoch 42/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 4.1431 - val_accuracy: 0.3878\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.87641\n",
      "Epoch 43/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.3412 - val_accuracy: 0.4898\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.87641\n",
      "Epoch 44/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0207 - accuracy: 0.9915 - val_loss: 4.5327 - val_accuracy: 0.3469\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.87641\n",
      "Epoch 45/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0095 - accuracy: 0.9949 - val_loss: 2.8793 - val_accuracy: 0.5510\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.87641\n",
      "Epoch 46/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0226 - accuracy: 0.9949 - val_loss: 1.9994 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.87641\n",
      "Epoch 47/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0723 - accuracy: 0.9863 - val_loss: 3.0952 - val_accuracy: 0.5102\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.87641\n",
      "Epoch 48/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 2.1959 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.87641\n",
      "Epoch 49/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0175 - accuracy: 0.9915 - val_loss: 1.6093 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.87641 to 1.60928, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 50/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 2.1974 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.60928\n",
      "Epoch 51/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9949 - val_loss: 2.7224 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.60928\n",
      "Epoch 52/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 3.3999 - val_accuracy: 0.5306\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.60928\n",
      "Epoch 53/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 4.1801 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.60928\n",
      "Epoch 54/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.5667 - val_accuracy: 0.5442\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.60928\n",
      "Epoch 55/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3059 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.60928\n",
      "Epoch 56/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9966 - val_loss: 2.6490 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.60928\n",
      "Epoch 57/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8979 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.60928\n",
      "Epoch 58/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.6603e-04 - accuracy: 1.0000 - val_loss: 2.6894 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.60928\n",
      "Epoch 59/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 4.5206 - val_accuracy: 0.4014\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.60928\n",
      "Epoch 60/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 2.2210 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.60928\n",
      "Epoch 61/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 3.5173 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.60928\n",
      "Epoch 62/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.7950 - val_accuracy: 0.4558\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.60928\n",
      "Epoch 63/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.2778 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.60928\n",
      "Epoch 64/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9966 - val_loss: 3.3384 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.60928\n",
      "Epoch 65/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 3.4427 - val_accuracy: 0.5578\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.60928\n",
      "Epoch 66/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 3.3758 - val_accuracy: 0.5510\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.60928\n",
      "Epoch 67/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 1.5121 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.60928 to 1.51206, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 68/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0393 - accuracy: 0.9897 - val_loss: 2.0983 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.51206\n",
      "Epoch 69/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.9846 - val_loss: 2.7285 - val_accuracy: 0.5578\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.51206\n",
      "Epoch 70/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0338 - accuracy: 0.9863 - val_loss: 1.8553 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.51206\n",
      "Epoch 71/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.9148 - val_accuracy: 0.7823\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.51206 to 0.91480, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 72/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.91480\n",
      "Epoch 73/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 3.2615 - val_accuracy: 0.5306\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.91480\n",
      "Epoch 74/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 2.5968 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.91480\n",
      "Epoch 75/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0336 - accuracy: 0.9863 - val_loss: 2.2865 - val_accuracy: 0.5578\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.91480\n",
      "Epoch 76/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 2.0393 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.91480\n",
      "Epoch 77/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0396 - accuracy: 0.9897 - val_loss: 5.2953 - val_accuracy: 0.3129\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.91480\n",
      "Epoch 78/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9915 - val_loss: 7.1916 - val_accuracy: 0.2993\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.91480\n",
      "Epoch 79/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0297 - accuracy: 0.9932 - val_loss: 5.5659 - val_accuracy: 0.3878\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.91480\n",
      "Epoch 80/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0255 - accuracy: 0.9846 - val_loss: 2.7218 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.91480\n",
      "Epoch 81/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0602 - accuracy: 0.9829 - val_loss: 1.2369 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.91480\n",
      "Epoch 82/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 1.3444 - val_accuracy: 0.7891\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.91480\n",
      "Epoch 83/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 0.6178 - val_accuracy: 0.8367\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.91480 to 0.61783, saving model to model_normalize_best(cv1).h5\n",
      "Epoch 84/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.6585 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.61783\n",
      "Epoch 85/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 2.1683 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.61783\n",
      "Epoch 86/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0086 - accuracy: 0.9949 - val_loss: 2.2044 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.61783\n",
      "Epoch 87/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0118 - accuracy: 0.9949 - val_loss: 2.9811 - val_accuracy: 0.5510\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.61783\n",
      "Epoch 88/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 3.2271 - val_accuracy: 0.5442\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.61783\n",
      "Epoch 89/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.0299e-04 - accuracy: 1.0000 - val_loss: 2.6625 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.61783\n",
      "Epoch 90/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9550e-04 - accuracy: 1.0000 - val_loss: 2.8586 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.61783\n",
      "Epoch 91/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.7622e-05 - accuracy: 1.0000 - val_loss: 2.9508 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.61783\n",
      "Epoch 92/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8892e-04 - accuracy: 1.0000 - val_loss: 2.9548 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.61783\n",
      "Epoch 93/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2221e-04 - accuracy: 1.0000 - val_loss: 2.9140 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.61783\n",
      "Epoch 94/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.6596e-04 - accuracy: 1.0000 - val_loss: 2.8266 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.61783\n",
      "Epoch 95/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5399e-04 - accuracy: 1.0000 - val_loss: 2.7266 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.61783\n",
      "Epoch 96/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.2161e-04 - accuracy: 1.0000 - val_loss: 3.1347 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.61783\n",
      "Epoch 97/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7532e-05 - accuracy: 1.0000 - val_loss: 3.3388 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.61783\n",
      "Epoch 98/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.4102e-05 - accuracy: 1.0000 - val_loss: 3.3201 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.61783\n",
      "Epoch 99/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0390e-04 - accuracy: 1.0000 - val_loss: 3.2034 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.61783\n",
      "Epoch 100/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0704 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.61783\n",
      "Epoch 101/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.5156e-05 - accuracy: 1.0000 - val_loss: 2.6437 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.61783\n",
      "Epoch 102/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.7103e-04 - accuracy: 1.0000 - val_loss: 2.6609 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.61783\n",
      "Epoch 103/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9443e-04 - accuracy: 1.0000 - val_loss: 2.6639 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.61783\n",
      "Epoch 104/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2663e-04 - accuracy: 1.0000 - val_loss: 2.6720 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.61783\n",
      "Epoch 105/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6724e-05 - accuracy: 1.0000 - val_loss: 2.6720 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.61783\n",
      "Epoch 106/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.5099e-04 - accuracy: 1.0000 - val_loss: 2.6959 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.61783\n",
      "Epoch 107/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5172e-04 - accuracy: 1.0000 - val_loss: 2.6991 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.61783\n",
      "Epoch 108/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5118e-04 - accuracy: 1.0000 - val_loss: 2.7201 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.61783\n",
      "Epoch 109/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.2761e-05 - accuracy: 1.0000 - val_loss: 2.7196 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.61783\n",
      "Epoch 110/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6485e-05 - accuracy: 1.0000 - val_loss: 2.7274 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.61783\n",
      "Epoch 111/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2589e-05 - accuracy: 1.0000 - val_loss: 2.7264 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.61783\n",
      "Epoch 112/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8097e-04 - accuracy: 1.0000 - val_loss: 2.7180 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.61783\n",
      "Epoch 113/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1263e-04 - accuracy: 1.0000 - val_loss: 2.7234 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.61783\n",
      "Epoch 114/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.4380e-05 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.61783\n",
      "Epoch 115/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6840 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.61783\n",
      "Epoch 116/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1192e-05 - accuracy: 1.0000 - val_loss: 2.6413 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.61783\n",
      "Epoch 117/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0923e-04 - accuracy: 1.0000 - val_loss: 2.6477 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.61783\n",
      "Epoch 118/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8984e-05 - accuracy: 1.0000 - val_loss: 2.6205 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.61783\n",
      "Epoch 119/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5937 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.61783\n",
      "Epoch 120/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.9945e-04 - accuracy: 1.0000 - val_loss: 2.5484 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.61783\n",
      "Epoch 121/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4765e-05 - accuracy: 1.0000 - val_loss: 2.6060 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.61783\n",
      "Epoch 122/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8687e-05 - accuracy: 1.0000 - val_loss: 2.6060 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.61783\n",
      "Epoch 123/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.3444e-05 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.61783\n",
      "Epoch 124/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7259e-04 - accuracy: 1.0000 - val_loss: 2.6119 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.61783\n",
      "Epoch 125/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.6884e-05 - accuracy: 1.0000 - val_loss: 2.6187 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.61783\n",
      "Epoch 126/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8522e-05 - accuracy: 1.0000 - val_loss: 2.6425 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.61783\n",
      "Epoch 127/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 2.6980 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.61783\n",
      "Epoch 128/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4899e-05 - accuracy: 1.0000 - val_loss: 2.7515 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.61783\n",
      "Epoch 129/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.8974e-05 - accuracy: 1.0000 - val_loss: 2.7775 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.61783\n",
      "Epoch 130/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1565e-04 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.61783\n",
      "Epoch 131/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1720e-05 - accuracy: 1.0000 - val_loss: 2.7621 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.61783\n",
      "Epoch 132/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.2627e-05 - accuracy: 1.0000 - val_loss: 2.7617 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.61783\n",
      "Epoch 133/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.7639e-05 - accuracy: 1.0000 - val_loss: 2.7571 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.61783\n",
      "Epoch 134/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.0807e-05 - accuracy: 1.0000 - val_loss: 2.7648 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.61783\n",
      "Epoch 135/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0205e-04 - accuracy: 1.0000 - val_loss: 2.7646 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.61783\n",
      "Epoch 136/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1085e-05 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.61783\n",
      "Epoch 137/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2513e-05 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.61783\n",
      "Epoch 138/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8315e-05 - accuracy: 1.0000 - val_loss: 2.7781 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.61783\n",
      "Epoch 139/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2910e-05 - accuracy: 1.0000 - val_loss: 2.7667 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.61783\n",
      "Epoch 140/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.1373e-04 - accuracy: 1.0000 - val_loss: 2.7427 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.61783\n",
      "Epoch 141/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9463e-04 - accuracy: 1.0000 - val_loss: 2.7336 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.61783\n",
      "Epoch 142/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9253e-04 - accuracy: 1.0000 - val_loss: 2.7099 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.61783\n",
      "Epoch 143/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.5543e-05 - accuracy: 1.0000 - val_loss: 2.7340 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.61783\n",
      "Epoch 144/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1900e-05 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.61783\n",
      "Epoch 145/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.2904e-05 - accuracy: 1.0000 - val_loss: 2.7250 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.61783\n",
      "Epoch 146/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3327e-05 - accuracy: 1.0000 - val_loss: 2.7217 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.61783\n",
      "Epoch 147/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.0831e-05 - accuracy: 1.0000 - val_loss: 2.7113 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.61783\n",
      "Epoch 148/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8424e-05 - accuracy: 1.0000 - val_loss: 2.7347 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.61783\n",
      "Epoch 149/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8797e-05 - accuracy: 1.0000 - val_loss: 2.7548 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.61783\n",
      "Epoch 150/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7032e-05 - accuracy: 1.0000 - val_loss: 2.7718 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.61783\n",
      "Epoch 151/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8791e-05 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.61783\n",
      "Epoch 152/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3418e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.61783\n",
      "Epoch 153/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0073e-05 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.61783\n",
      "Epoch 154/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8729e-04 - accuracy: 1.0000 - val_loss: 2.7837 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.61783\n",
      "Epoch 155/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.2599e-05 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.61783\n",
      "Epoch 156/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7229e-05 - accuracy: 1.0000 - val_loss: 2.7890 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.61783\n",
      "Epoch 157/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0244e-05 - accuracy: 1.0000 - val_loss: 2.7664 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.61783\n",
      "Epoch 158/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8552e-04 - accuracy: 1.0000 - val_loss: 2.7557 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.61783\n",
      "Epoch 159/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1162e-05 - accuracy: 1.0000 - val_loss: 2.7815 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.61783\n",
      "Epoch 160/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.5966e-05 - accuracy: 1.0000 - val_loss: 2.7727 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.61783\n",
      "Epoch 161/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.1882e-05 - accuracy: 1.0000 - val_loss: 2.7566 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.61783\n",
      "Epoch 162/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.7898e-05 - accuracy: 1.0000 - val_loss: 2.7527 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.61783\n",
      "Epoch 163/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6972e-05 - accuracy: 1.0000 - val_loss: 2.7683 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.61783\n",
      "Epoch 164/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4984e-05 - accuracy: 1.0000 - val_loss: 2.7704 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.61783\n",
      "Epoch 165/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7235e-05 - accuracy: 1.0000 - val_loss: 2.7591 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.61783\n",
      "Epoch 166/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8801e-04 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.61783\n",
      "Epoch 167/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4761e-04 - accuracy: 1.0000 - val_loss: 2.7639 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.61783\n",
      "Epoch 168/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2503e-04 - accuracy: 1.0000 - val_loss: 2.7840 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.61783\n",
      "Epoch 169/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8037e-05 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.61783\n",
      "Epoch 170/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7172e-05 - accuracy: 1.0000 - val_loss: 2.8061 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.61783\n",
      "Epoch 171/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0620e-05 - accuracy: 1.0000 - val_loss: 2.8325 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.61783\n",
      "Epoch 172/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0017 - accuracy: 0.9983 - val_loss: 2.8490 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.61783\n",
      "Epoch 173/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7599e-04 - accuracy: 1.0000 - val_loss: 3.0019 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.61783\n",
      "Epoch 174/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9000e-05 - accuracy: 1.0000 - val_loss: 2.9784 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.61783\n",
      "Epoch 175/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1896e-05 - accuracy: 1.0000 - val_loss: 2.9680 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.61783\n",
      "Epoch 176/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.3661e-05 - accuracy: 1.0000 - val_loss: 2.9625 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.61783\n",
      "Epoch 177/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4064e-04 - accuracy: 1.0000 - val_loss: 2.9657 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.61783\n",
      "Epoch 178/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8418e-05 - accuracy: 1.0000 - val_loss: 2.9407 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.61783\n",
      "Epoch 179/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7284e-05 - accuracy: 1.0000 - val_loss: 2.9172 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.61783\n",
      "Epoch 180/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.2456e-05 - accuracy: 1.0000 - val_loss: 2.9254 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.61783\n",
      "Epoch 181/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2282e-05 - accuracy: 1.0000 - val_loss: 2.9294 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.61783\n",
      "Epoch 182/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.7812e-05 - accuracy: 1.0000 - val_loss: 2.9300 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.61783\n",
      "Epoch 183/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.0765e-05 - accuracy: 1.0000 - val_loss: 2.9375 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.61783\n",
      "Epoch 184/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4527e-04 - accuracy: 1.0000 - val_loss: 2.9198 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.61783\n",
      "Epoch 185/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.6393e-05 - accuracy: 1.0000 - val_loss: 2.9158 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.61783\n",
      "Epoch 186/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9315e-05 - accuracy: 1.0000 - val_loss: 2.9206 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.61783\n",
      "Epoch 187/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.3244e-05 - accuracy: 1.0000 - val_loss: 2.9391 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.61783\n",
      "Epoch 188/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7704e-05 - accuracy: 1.0000 - val_loss: 2.9265 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.61783\n",
      "Epoch 189/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.7874e-04 - accuracy: 1.0000 - val_loss: 2.9315 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.61783\n",
      "Epoch 190/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4445e-04 - accuracy: 1.0000 - val_loss: 2.9587 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.61783\n",
      "Epoch 191/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1465e-05 - accuracy: 1.0000 - val_loss: 2.9771 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.61783\n",
      "Epoch 192/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4345e-04 - accuracy: 1.0000 - val_loss: 2.9906 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.61783\n",
      "Epoch 193/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3640e-05 - accuracy: 1.0000 - val_loss: 3.0149 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.61783\n",
      "Epoch 194/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5101e-04 - accuracy: 1.0000 - val_loss: 3.0016 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.61783\n",
      "Epoch 195/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.8055e-05 - accuracy: 1.0000 - val_loss: 2.9907 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.61783\n",
      "Epoch 196/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3084e-04 - accuracy: 1.0000 - val_loss: 2.9897 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.61783\n",
      "Epoch 197/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8186e-05 - accuracy: 1.0000 - val_loss: 2.9964 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.61783\n",
      "Epoch 198/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5510e-05 - accuracy: 1.0000 - val_loss: 2.9877 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.61783\n",
      "Epoch 199/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9559e-04 - accuracy: 1.0000 - val_loss: 2.9750 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.61783\n",
      "Epoch 200/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5401e-05 - accuracy: 1.0000 - val_loss: 2.9776 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.61783\n",
      "Epoch 201/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1213e-05 - accuracy: 1.0000 - val_loss: 2.9898 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.61783\n",
      "Epoch 202/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7511e-05 - accuracy: 1.0000 - val_loss: 2.9794 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.61783\n",
      "Epoch 203/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5462e-05 - accuracy: 1.0000 - val_loss: 2.9786 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.61783\n",
      "Epoch 204/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4265e-05 - accuracy: 1.0000 - val_loss: 2.9977 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.61783\n",
      "Epoch 205/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4410e-05 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.61783\n",
      "Epoch 206/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.0226e-05 - accuracy: 1.0000 - val_loss: 2.9847 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.61783\n",
      "Epoch 207/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9179e-05 - accuracy: 1.0000 - val_loss: 2.9794 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.61783\n",
      "Epoch 208/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.0498e-05 - accuracy: 1.0000 - val_loss: 2.9926 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.61783\n",
      "Epoch 209/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0027e-04 - accuracy: 1.0000 - val_loss: 2.9828 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.61783\n",
      "Epoch 210/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6665e-05 - accuracy: 1.0000 - val_loss: 2.9721 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.61783\n",
      "Epoch 211/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5292e-05 - accuracy: 1.0000 - val_loss: 2.9563 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.61783\n",
      "Epoch 212/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8247e-05 - accuracy: 1.0000 - val_loss: 2.9531 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.61783\n",
      "Epoch 213/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3484e-05 - accuracy: 1.0000 - val_loss: 2.9565 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.61783\n",
      "Epoch 214/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9881e-05 - accuracy: 1.0000 - val_loss: 2.9641 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.61783\n",
      "Epoch 215/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8455e-05 - accuracy: 1.0000 - val_loss: 2.9658 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.61783\n",
      "Epoch 216/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5324e-05 - accuracy: 1.0000 - val_loss: 2.9640 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.61783\n",
      "Epoch 217/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2668e-06 - accuracy: 1.0000 - val_loss: 2.9634 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.61783\n",
      "Epoch 218/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1208e-04 - accuracy: 1.0000 - val_loss: 2.9501 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.61783\n",
      "Epoch 219/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5349e-05 - accuracy: 1.0000 - val_loss: 2.9177 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.61783\n",
      "Epoch 220/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9189e-05 - accuracy: 1.0000 - val_loss: 2.8762 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.61783\n",
      "Epoch 221/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8918e-05 - accuracy: 1.0000 - val_loss: 2.8959 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.61783\n",
      "Epoch 222/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1610e-05 - accuracy: 1.0000 - val_loss: 2.9218 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.61783\n",
      "Epoch 223/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.9125e-05 - accuracy: 1.0000 - val_loss: 2.9101 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.61783\n",
      "Epoch 224/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.8042e-06 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.61783\n",
      "Epoch 225/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0813e-04 - accuracy: 1.0000 - val_loss: 2.9052 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.61783\n",
      "Epoch 226/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2442e-05 - accuracy: 1.0000 - val_loss: 2.9217 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.61783\n",
      "Epoch 227/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4732e-05 - accuracy: 1.0000 - val_loss: 2.9085 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.61783\n",
      "Epoch 228/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9840e-05 - accuracy: 1.0000 - val_loss: 2.9117 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.61783\n",
      "Epoch 229/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3207e-05 - accuracy: 1.0000 - val_loss: 2.8884 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.61783\n",
      "Epoch 230/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7236e-05 - accuracy: 1.0000 - val_loss: 2.9095 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.61783\n",
      "Epoch 231/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6844e-05 - accuracy: 1.0000 - val_loss: 2.9003 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.61783\n",
      "Epoch 232/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8397e-05 - accuracy: 1.0000 - val_loss: 2.9257 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.61783\n",
      "Epoch 233/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0001e-05 - accuracy: 1.0000 - val_loss: 2.9360 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.61783\n",
      "Epoch 234/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4525e-04 - accuracy: 1.0000 - val_loss: 2.9507 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.61783\n",
      "Epoch 235/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.2539e-05 - accuracy: 1.0000 - val_loss: 2.9873 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.61783\n",
      "Epoch 236/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8271e-04 - accuracy: 1.0000 - val_loss: 2.9366 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.61783\n",
      "Epoch 237/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7845e-05 - accuracy: 1.0000 - val_loss: 2.9418 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.61783\n",
      "Epoch 238/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9234e-05 - accuracy: 1.0000 - val_loss: 2.9363 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.61783\n",
      "Epoch 239/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.0790e-05 - accuracy: 1.0000 - val_loss: 2.9458 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.61783\n",
      "Epoch 240/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8445e-05 - accuracy: 1.0000 - val_loss: 2.9473 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.61783\n",
      "Epoch 241/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9597e-05 - accuracy: 1.0000 - val_loss: 2.9661 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.61783\n",
      "Epoch 242/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5816e-04 - accuracy: 1.0000 - val_loss: 2.9000 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.61783\n",
      "Epoch 243/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6037e-05 - accuracy: 1.0000 - val_loss: 2.8920 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.61783\n",
      "Epoch 244/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1108e-05 - accuracy: 1.0000 - val_loss: 2.8870 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.61783\n",
      "Epoch 245/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4105e-05 - accuracy: 1.0000 - val_loss: 2.9064 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.61783\n",
      "Epoch 246/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3896e-05 - accuracy: 1.0000 - val_loss: 2.8999 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.61783\n",
      "Epoch 247/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.9626e-06 - accuracy: 1.0000 - val_loss: 2.8893 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.61783\n",
      "Epoch 248/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.9534e-05 - accuracy: 1.0000 - val_loss: 2.8983 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.61783\n",
      "Epoch 249/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6443e-05 - accuracy: 1.0000 - val_loss: 2.8909 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.61783\n",
      "Epoch 250/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1596e-05 - accuracy: 1.0000 - val_loss: 2.8799 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.61783\n",
      "Epoch 251/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6782e-05 - accuracy: 1.0000 - val_loss: 2.8965 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.61783\n",
      "Epoch 252/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1211e-04 - accuracy: 1.0000 - val_loss: 2.8969 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.61783\n",
      "Epoch 253/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7852e-05 - accuracy: 1.0000 - val_loss: 2.9121 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.61783\n",
      "Epoch 254/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2040e-04 - accuracy: 1.0000 - val_loss: 2.9334 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.61783\n",
      "Epoch 255/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.2333e-05 - accuracy: 1.0000 - val_loss: 2.9258 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.61783\n",
      "Epoch 256/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5499e-05 - accuracy: 1.0000 - val_loss: 2.9226 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.61783\n",
      "Epoch 257/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3252e-05 - accuracy: 1.0000 - val_loss: 2.9195 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.61783\n",
      "Epoch 258/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.8706e-06 - accuracy: 1.0000 - val_loss: 2.9375 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.61783\n",
      "Epoch 259/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2842e-04 - accuracy: 1.0000 - val_loss: 2.9659 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.61783\n",
      "Epoch 260/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6677e-05 - accuracy: 1.0000 - val_loss: 2.9886 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.61783\n",
      "Epoch 261/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3808e-04 - accuracy: 1.0000 - val_loss: 2.9861 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.61783\n",
      "Epoch 262/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5019e-05 - accuracy: 1.0000 - val_loss: 2.9828 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.61783\n",
      "Epoch 263/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.9146e-06 - accuracy: 1.0000 - val_loss: 2.9679 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.61783\n",
      "Epoch 264/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.8340e-05 - accuracy: 1.0000 - val_loss: 2.9782 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.61783\n",
      "Epoch 265/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.0071e-05 - accuracy: 1.0000 - val_loss: 2.9918 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.61783\n",
      "Epoch 266/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.0347e-05 - accuracy: 1.0000 - val_loss: 2.9864 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.61783\n",
      "Epoch 267/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4752e-05 - accuracy: 1.0000 - val_loss: 2.9733 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.61783\n",
      "Epoch 268/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9937e-05 - accuracy: 1.0000 - val_loss: 2.9780 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.61783\n",
      "Epoch 269/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8755e-04 - accuracy: 1.0000 - val_loss: 3.0321 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.61783\n",
      "Epoch 270/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.1367e-06 - accuracy: 1.0000 - val_loss: 3.1325 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.61783\n",
      "Epoch 271/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3864e-06 - accuracy: 1.0000 - val_loss: 3.1220 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.61783\n",
      "Epoch 272/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.4823e-05 - accuracy: 1.0000 - val_loss: 3.1041 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.61783\n",
      "Epoch 273/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.7264e-05 - accuracy: 1.0000 - val_loss: 3.0974 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.61783\n",
      "Epoch 274/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8228e-05 - accuracy: 1.0000 - val_loss: 3.0850 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.61783\n",
      "Epoch 275/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4283e-05 - accuracy: 1.0000 - val_loss: 3.0696 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.61783\n",
      "Epoch 276/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0264e-05 - accuracy: 1.0000 - val_loss: 3.0618 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.61783\n",
      "Epoch 277/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9595e-05 - accuracy: 1.0000 - val_loss: 3.0408 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.61783\n",
      "Epoch 278/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6835e-05 - accuracy: 1.0000 - val_loss: 3.0420 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.61783\n",
      "Epoch 279/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7195e-05 - accuracy: 1.0000 - val_loss: 3.0498 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.61783\n",
      "Epoch 280/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2281e-05 - accuracy: 1.0000 - val_loss: 3.0339 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.61783\n",
      "Epoch 281/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.3731e-05 - accuracy: 1.0000 - val_loss: 3.0398 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.61783\n",
      "Epoch 282/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5855e-05 - accuracy: 1.0000 - val_loss: 3.0260 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.61783\n",
      "Epoch 283/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0844e-05 - accuracy: 1.0000 - val_loss: 3.0410 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.61783\n",
      "Epoch 284/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8028e-05 - accuracy: 1.0000 - val_loss: 3.0521 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.61783\n",
      "Epoch 285/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4578e-05 - accuracy: 1.0000 - val_loss: 3.0445 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.61783\n",
      "Epoch 286/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0738e-05 - accuracy: 1.0000 - val_loss: 3.0522 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.61783\n",
      "Epoch 287/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3450e-05 - accuracy: 1.0000 - val_loss: 3.0345 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.61783\n",
      "Epoch 288/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8595e-05 - accuracy: 1.0000 - val_loss: 3.0372 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.61783\n",
      "Epoch 289/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0191e-05 - accuracy: 1.0000 - val_loss: 3.0273 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.61783\n",
      "Epoch 290/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8423e-05 - accuracy: 1.0000 - val_loss: 3.0143 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.61783\n",
      "Epoch 291/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.4218e-05 - accuracy: 1.0000 - val_loss: 3.0055 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.61783\n",
      "Epoch 292/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1534e-05 - accuracy: 1.0000 - val_loss: 3.0066 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.61783\n",
      "Epoch 293/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0134e-05 - accuracy: 1.0000 - val_loss: 3.0136 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.61783\n",
      "Epoch 294/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1313e-05 - accuracy: 1.0000 - val_loss: 3.0374 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.61783\n",
      "Epoch 295/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9018e-05 - accuracy: 1.0000 - val_loss: 3.0273 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.61783\n",
      "Epoch 296/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2554e-06 - accuracy: 1.0000 - val_loss: 3.0224 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.61783\n",
      "Epoch 297/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5787e-05 - accuracy: 1.0000 - val_loss: 3.0360 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.61783\n",
      "Epoch 298/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7996e-05 - accuracy: 1.0000 - val_loss: 3.0593 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.61783\n",
      "Epoch 299/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.4459e-05 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.61783\n",
      "Epoch 300/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3051e-05 - accuracy: 1.0000 - val_loss: 3.0547 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.61783\n",
      "predict test data\n",
      "183/183 [==============================] - 10s 56ms/step\n",
      "../npy/2\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "(732, 256, 256, 3)\n",
      "(732, 1)\n",
      "../npy/2\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(183, 256, 256, 3)\n",
      "(183, 1)\n",
      "(732, 1)\n",
      "(183, 1)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 2 0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 2 0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 2 0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 5 0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 5 0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 5 0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 5 0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 1 0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 2 0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 2 0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4098        global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/300\n",
      "585/585 [==============================] - 21s 35ms/step - loss: 0.7934 - accuracy: 0.6923 - val_loss: 6.7921 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.79208, saving model to model_normalize_best(cv2).h5\n",
      "Epoch 2/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.3325 - accuracy: 0.8547 - val_loss: 6.7318 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.79208 to 6.73180, saving model to model_normalize_best(cv2).h5\n",
      "Epoch 3/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1209 - accuracy: 0.9607 - val_loss: 9.2354 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 6.73180\n",
      "Epoch 4/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0654 - accuracy: 0.9761 - val_loss: 10.8842 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.73180\n",
      "Epoch 5/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0882 - accuracy: 0.9744 - val_loss: 8.9336 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.73180\n",
      "Epoch 6/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 12.7484 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.73180\n",
      "Epoch 7/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1081 - accuracy: 0.9607 - val_loss: 13.4860 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.73180\n",
      "Epoch 8/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0890 - accuracy: 0.9675 - val_loss: 14.5607 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.73180\n",
      "Epoch 9/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0817 - accuracy: 0.9641 - val_loss: 13.6640 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 6.73180\n",
      "Epoch 10/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0655 - accuracy: 0.9726 - val_loss: 13.0622 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.73180\n",
      "Epoch 11/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0438 - accuracy: 0.9880 - val_loss: 15.3146 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 6.73180\n",
      "Epoch 12/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0594 - accuracy: 0.9761 - val_loss: 13.2939 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 6.73180\n",
      "Epoch 13/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0648 - accuracy: 0.9795 - val_loss: 10.8357 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 6.73180\n",
      "Epoch 14/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1063 - accuracy: 0.9573 - val_loss: 10.9737 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.73180\n",
      "Epoch 15/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0844 - accuracy: 0.9641 - val_loss: 13.5685 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6.73180\n",
      "Epoch 16/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0746 - accuracy: 0.9675 - val_loss: 11.6776 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 6.73180\n",
      "Epoch 17/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 11.2980 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 6.73180\n",
      "Epoch 18/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0376 - accuracy: 0.9863 - val_loss: 11.2281 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 6.73180\n",
      "Epoch 19/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0705 - accuracy: 0.9726 - val_loss: 11.6305 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 6.73180\n",
      "Epoch 20/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0593 - accuracy: 0.9795 - val_loss: 9.7422 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 6.73180\n",
      "Epoch 21/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0269 - accuracy: 0.9897 - val_loss: 10.5664 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 6.73180\n",
      "Epoch 22/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 11.0450 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 6.73180\n",
      "Epoch 23/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0224 - accuracy: 0.9897 - val_loss: 11.0936 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 6.73180\n",
      "Epoch 24/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 11.3962 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 6.73180\n",
      "Epoch 25/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 13.0729 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 6.73180\n",
      "Epoch 26/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0599 - accuracy: 0.9863 - val_loss: 11.0550 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 6.73180\n",
      "Epoch 27/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0464 - accuracy: 0.9880 - val_loss: 10.9180 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 6.73180\n",
      "Epoch 28/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 10.8948 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 6.73180\n",
      "Epoch 29/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 9.4266 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 6.73180\n",
      "Epoch 30/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0089 - accuracy: 0.9949 - val_loss: 10.8565 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 6.73180\n",
      "Epoch 31/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 11.9290 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 6.73180\n",
      "Epoch 32/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 8.9772 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 6.73180\n",
      "Epoch 33/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 9.6875 - val_accuracy: 0.0204\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 6.73180\n",
      "Epoch 34/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0373 - accuracy: 0.9846 - val_loss: 4.6646 - val_accuracy: 0.2585\n",
      "\n",
      "Epoch 00034: val_loss improved from 6.73180 to 4.66461, saving model to model_normalize_best(cv2).h5\n",
      "Epoch 35/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 2.2744 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00035: val_loss improved from 4.66461 to 2.27445, saving model to model_normalize_best(cv2).h5\n",
      "Epoch 36/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0911 - accuracy: 0.9761 - val_loss: 7.1265 - val_accuracy: 0.2585\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.27445\n",
      "Epoch 37/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0871 - accuracy: 0.9726 - val_loss: 5.4200 - val_accuracy: 0.0544\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.27445\n",
      "Epoch 38/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 6.4724 - val_accuracy: 0.1293\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.27445\n",
      "Epoch 39/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 4.6448 - val_accuracy: 0.2449\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.27445\n",
      "Epoch 40/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 2.7806 - val_accuracy: 0.4898\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.27445\n",
      "Epoch 41/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.3513 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.27445\n",
      "Epoch 42/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 4.2269 - val_accuracy: 0.4150\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.27445\n",
      "Epoch 43/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9983 - val_loss: 4.3733 - val_accuracy: 0.3673\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.27445\n",
      "Epoch 44/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0106 - accuracy: 0.9949 - val_loss: 2.7735 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.27445\n",
      "Epoch 45/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 2.6486 - val_accuracy: 0.5306\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.27445\n",
      "Epoch 46/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.8963 - val_accuracy: 0.4626\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.27445\n",
      "Epoch 47/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7991 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.27445 to 1.79914, saving model to model_normalize_best(cv2).h5\n",
      "Epoch 48/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0054 - accuracy: 0.9966 - val_loss: 1.9360 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.79914\n",
      "Epoch 49/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0983e-04 - accuracy: 1.0000 - val_loss: 2.0093 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.79914\n",
      "Epoch 50/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0394 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.79914\n",
      "Epoch 51/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4622e-04 - accuracy: 1.0000 - val_loss: 2.1453 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.79914\n",
      "Epoch 52/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1317 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.79914\n",
      "Epoch 53/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9330e-04 - accuracy: 1.0000 - val_loss: 2.1812 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.79914\n",
      "Epoch 54/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3158e-04 - accuracy: 1.0000 - val_loss: 2.1797 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.79914\n",
      "Epoch 55/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.9346e-05 - accuracy: 1.0000 - val_loss: 2.1835 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.79914\n",
      "Epoch 56/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.1047e-04 - accuracy: 1.0000 - val_loss: 2.1869 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.79914\n",
      "Epoch 57/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.1848e-05 - accuracy: 1.0000 - val_loss: 2.1727 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.79914\n",
      "Epoch 58/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.3075e-04 - accuracy: 1.0000 - val_loss: 2.2231 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.79914\n",
      "Epoch 59/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4072e-04 - accuracy: 1.0000 - val_loss: 2.2231 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.79914\n",
      "Epoch 60/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.9515e-04 - accuracy: 1.0000 - val_loss: 2.2251 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.79914\n",
      "Epoch 61/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2096e-04 - accuracy: 1.0000 - val_loss: 2.2926 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.79914\n",
      "Epoch 62/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.8973e-05 - accuracy: 1.0000 - val_loss: 2.3254 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.79914\n",
      "Epoch 63/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0310e-04 - accuracy: 1.0000 - val_loss: 2.3143 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.79914\n",
      "Epoch 64/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6626e-04 - accuracy: 1.0000 - val_loss: 2.2595 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.79914\n",
      "Epoch 65/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3612e-04 - accuracy: 1.0000 - val_loss: 2.2759 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.79914\n",
      "Epoch 66/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5926e-04 - accuracy: 1.0000 - val_loss: 2.2377 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.79914\n",
      "Epoch 67/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.5033e-04 - accuracy: 1.0000 - val_loss: 2.0342 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.79914\n",
      "Epoch 68/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.3402e-05 - accuracy: 1.0000 - val_loss: 2.0064 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.79914\n",
      "Epoch 69/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3392e-05 - accuracy: 1.0000 - val_loss: 2.0026 - val_accuracy: 0.7007\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.79914\n",
      "Epoch 70/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 9.1289e-05 - accuracy: 1.0000 - val_loss: 2.0633 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.79914\n",
      "Epoch 71/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.7309e-05 - accuracy: 1.0000 - val_loss: 2.0708 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.79914\n",
      "Epoch 72/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1441e-04 - accuracy: 1.0000 - val_loss: 2.1311 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.79914\n",
      "Epoch 73/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0362e-04 - accuracy: 1.0000 - val_loss: 2.2347 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.79914\n",
      "Epoch 74/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0195e-04 - accuracy: 1.0000 - val_loss: 2.2384 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.79914\n",
      "Epoch 75/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4123e-05 - accuracy: 1.0000 - val_loss: 2.2350 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.79914\n",
      "Epoch 76/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.1463e-04 - accuracy: 1.0000 - val_loss: 2.6887 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.79914\n",
      "Epoch 77/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.0698e-05 - accuracy: 1.0000 - val_loss: 2.7654 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.79914\n",
      "Epoch 78/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.3050e-04 - accuracy: 1.0000 - val_loss: 3.9463 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.79914\n",
      "Epoch 79/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.6015e-04 - accuracy: 1.0000 - val_loss: 3.7878 - val_accuracy: 0.5034\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.79914\n",
      "Epoch 80/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0019 - accuracy: 0.9983 - val_loss: 2.1854 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.79914\n",
      "Epoch 81/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5862 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.79914\n",
      "Epoch 82/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.3679e-04 - accuracy: 1.0000 - val_loss: 2.9376 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.79914\n",
      "Epoch 83/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8383e-04 - accuracy: 1.0000 - val_loss: 2.3228 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.79914\n",
      "Epoch 84/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0668e-04 - accuracy: 1.0000 - val_loss: 2.0815 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.79914\n",
      "Epoch 85/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.3802e-05 - accuracy: 1.0000 - val_loss: 2.0930 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.79914\n",
      "Epoch 86/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1473e-05 - accuracy: 1.0000 - val_loss: 2.1355 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.79914\n",
      "Epoch 87/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.4080e-05 - accuracy: 1.0000 - val_loss: 2.2155 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.79914\n",
      "Epoch 88/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7154e-04 - accuracy: 1.0000 - val_loss: 2.3163 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.79914\n",
      "Epoch 89/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2225e-05 - accuracy: 1.0000 - val_loss: 2.3387 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.79914\n",
      "Epoch 90/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8019e-05 - accuracy: 1.0000 - val_loss: 2.3276 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.79914\n",
      "Epoch 91/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6615e-04 - accuracy: 1.0000 - val_loss: 2.2966 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.79914\n",
      "Epoch 92/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9801e-05 - accuracy: 1.0000 - val_loss: 2.3296 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.79914\n",
      "Epoch 93/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1296e-04 - accuracy: 1.0000 - val_loss: 2.3578 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.79914\n",
      "Epoch 94/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.6415e-05 - accuracy: 1.0000 - val_loss: 2.3791 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.79914\n",
      "Epoch 95/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 6.3968e-05 - accuracy: 1.0000 - val_loss: 2.4011 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.79914\n",
      "Epoch 96/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8247e-05 - accuracy: 1.0000 - val_loss: 2.3673 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.79914\n",
      "Epoch 97/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3339e-05 - accuracy: 1.0000 - val_loss: 2.3452 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.79914\n",
      "Epoch 98/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.7197e-05 - accuracy: 1.0000 - val_loss: 2.3438 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.79914\n",
      "Epoch 99/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4746e-05 - accuracy: 1.0000 - val_loss: 2.3520 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.79914\n",
      "Epoch 100/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.6681e-05 - accuracy: 1.0000 - val_loss: 2.3475 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.79914\n",
      "Epoch 101/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0598e-04 - accuracy: 1.0000 - val_loss: 2.4671 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.79914\n",
      "Epoch 102/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.2683e-05 - accuracy: 1.0000 - val_loss: 2.4681 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.79914\n",
      "Epoch 103/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0058e-05 - accuracy: 1.0000 - val_loss: 2.4447 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.79914\n",
      "Epoch 104/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - val_loss: 2.4195 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.79914\n",
      "Epoch 105/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7575e-04 - accuracy: 1.0000 - val_loss: 2.4043 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.79914\n",
      "Epoch 106/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.8847e-05 - accuracy: 1.0000 - val_loss: 2.4056 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.79914\n",
      "Epoch 107/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0035 - accuracy: 0.9966 - val_loss: 2.3237 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.79914\n",
      "Epoch 108/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5917e-04 - accuracy: 1.0000 - val_loss: 2.4143 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.79914\n",
      "Epoch 109/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.1736e-05 - accuracy: 1.0000 - val_loss: 2.4368 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.79914\n",
      "Epoch 110/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.3095e-05 - accuracy: 1.0000 - val_loss: 2.4302 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.79914\n",
      "Epoch 111/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2979e-05 - accuracy: 1.0000 - val_loss: 2.4475 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.79914\n",
      "Epoch 112/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1822e-04 - accuracy: 1.0000 - val_loss: 2.4981 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.79914\n",
      "Epoch 113/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1382e-04 - accuracy: 1.0000 - val_loss: 2.4734 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.79914\n",
      "Epoch 114/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.1932e-05 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.79914\n",
      "Epoch 115/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 2.6935 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.79914\n",
      "Epoch 116/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.2741e-05 - accuracy: 1.0000 - val_loss: 2.8261 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.79914\n",
      "Epoch 117/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 6.5533e-04 - accuracy: 1.0000 - val_loss: 2.8178 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.79914\n",
      "Epoch 118/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.7926e-04 - accuracy: 1.0000 - val_loss: 2.7455 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.79914\n",
      "Epoch 119/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5270e-05 - accuracy: 1.0000 - val_loss: 2.7037 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.79914\n",
      "Epoch 120/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1540e-04 - accuracy: 1.0000 - val_loss: 2.6269 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.79914\n",
      "Epoch 121/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5869e-05 - accuracy: 1.0000 - val_loss: 2.5904 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.79914\n",
      "Epoch 122/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 8.2857e-05 - accuracy: 1.0000 - val_loss: 2.5493 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.79914\n",
      "Epoch 123/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.5057e-05 - accuracy: 1.0000 - val_loss: 2.5357 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.79914\n",
      "Epoch 124/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.9932e-05 - accuracy: 1.0000 - val_loss: 2.5363 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.79914\n",
      "Epoch 125/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.5819e-04 - accuracy: 1.0000 - val_loss: 2.5742 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.79914\n",
      "Epoch 126/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.6909e-04 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.79914\n",
      "Epoch 127/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.6473e-04 - accuracy: 1.0000 - val_loss: 2.5649 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.79914\n",
      "Epoch 128/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.0432e-05 - accuracy: 1.0000 - val_loss: 2.5440 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.79914\n",
      "Epoch 129/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9271e-05 - accuracy: 1.0000 - val_loss: 2.5344 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.79914\n",
      "Epoch 130/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.2475e-05 - accuracy: 1.0000 - val_loss: 2.5068 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.79914\n",
      "Epoch 131/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2134e-05 - accuracy: 1.0000 - val_loss: 2.5033 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.79914\n",
      "Epoch 132/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4521e-05 - accuracy: 1.0000 - val_loss: 2.5015 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.79914\n",
      "Epoch 133/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.5612 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.79914\n",
      "Epoch 134/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6843e-05 - accuracy: 1.0000 - val_loss: 2.6740 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.79914\n",
      "Epoch 135/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8277e-04 - accuracy: 1.0000 - val_loss: 2.6555 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.79914\n",
      "Epoch 136/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5059e-05 - accuracy: 1.0000 - val_loss: 2.6326 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.79914\n",
      "Epoch 137/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.5605e-04 - accuracy: 1.0000 - val_loss: 2.6190 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.79914\n",
      "Epoch 138/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.7174e-04 - accuracy: 1.0000 - val_loss: 2.6369 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.79914\n",
      "Epoch 139/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.1462e-05 - accuracy: 1.0000 - val_loss: 2.7727 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.79914\n",
      "Epoch 140/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.5319e-06 - accuracy: 1.0000 - val_loss: 2.8014 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.79914\n",
      "Epoch 141/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.0241e-04 - accuracy: 1.0000 - val_loss: 2.8144 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.79914\n",
      "Epoch 142/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0626e-04 - accuracy: 1.0000 - val_loss: 2.7806 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.79914\n",
      "Epoch 143/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.0575e-04 - accuracy: 1.0000 - val_loss: 2.7344 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.79914\n",
      "Epoch 144/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.3415e-05 - accuracy: 1.0000 - val_loss: 2.7353 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.79914\n",
      "Epoch 145/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8162e-05 - accuracy: 1.0000 - val_loss: 2.7160 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.79914\n",
      "Epoch 146/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.3893e-05 - accuracy: 1.0000 - val_loss: 2.7007 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.79914\n",
      "Epoch 147/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3549e-05 - accuracy: 1.0000 - val_loss: 2.6896 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.79914\n",
      "Epoch 148/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.4171e-05 - accuracy: 1.0000 - val_loss: 2.6605 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.79914\n",
      "Epoch 149/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.6256e-05 - accuracy: 1.0000 - val_loss: 2.6732 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.79914\n",
      "Epoch 150/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.5232e-05 - accuracy: 1.0000 - val_loss: 2.6602 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.79914\n",
      "Epoch 151/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8316e-04 - accuracy: 1.0000 - val_loss: 2.6403 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.79914\n",
      "Epoch 152/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6062e-04 - accuracy: 1.0000 - val_loss: 2.6129 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.79914\n",
      "Epoch 153/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.1301e-05 - accuracy: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.79914\n",
      "Epoch 154/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.3561e-05 - accuracy: 1.0000 - val_loss: 2.5639 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.79914\n",
      "Epoch 155/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3778e-05 - accuracy: 1.0000 - val_loss: 2.5432 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.79914\n",
      "Epoch 156/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.7260e-05 - accuracy: 1.0000 - val_loss: 2.5565 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.79914\n",
      "Epoch 157/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.8074e-05 - accuracy: 1.0000 - val_loss: 2.5641 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.79914\n",
      "Epoch 158/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.2363e-05 - accuracy: 1.0000 - val_loss: 2.5714 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.79914\n",
      "Epoch 159/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.5721e-04 - accuracy: 1.0000 - val_loss: 2.4967 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.79914\n",
      "Epoch 160/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2781e-05 - accuracy: 1.0000 - val_loss: 2.4622 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.79914\n",
      "Epoch 161/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.4515e-06 - accuracy: 1.0000 - val_loss: 2.4488 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.79914\n",
      "Epoch 162/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8744e-05 - accuracy: 1.0000 - val_loss: 2.4610 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.79914\n",
      "Epoch 163/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.7746e-05 - accuracy: 1.0000 - val_loss: 2.4485 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.79914\n",
      "Epoch 164/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9605e-05 - accuracy: 1.0000 - val_loss: 2.4472 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.79914\n",
      "Epoch 165/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8032e-05 - accuracy: 1.0000 - val_loss: 2.4501 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.79914\n",
      "Epoch 166/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2888e-05 - accuracy: 1.0000 - val_loss: 2.4430 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.79914\n",
      "Epoch 167/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 8.9657e-05 - accuracy: 1.0000 - val_loss: 2.4271 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.79914\n",
      "Epoch 168/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.5178e-04 - accuracy: 1.0000 - val_loss: 2.3703 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.79914\n",
      "Epoch 169/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.1005e-04 - accuracy: 1.0000 - val_loss: 2.3638 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.79914\n",
      "Epoch 170/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.6819e-05 - accuracy: 1.0000 - val_loss: 2.3743 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.79914\n",
      "Epoch 171/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.3654e-06 - accuracy: 1.0000 - val_loss: 2.3825 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.79914\n",
      "Epoch 172/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2766e-06 - accuracy: 1.0000 - val_loss: 2.3834 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.79914\n",
      "Epoch 173/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 6.3328e-04 - accuracy: 1.0000 - val_loss: 2.5086 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.79914\n",
      "Epoch 174/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 6.4203e-06 - accuracy: 1.0000 - val_loss: 2.5555 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.79914\n",
      "Epoch 175/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.0636e-05 - accuracy: 1.0000 - val_loss: 2.5470 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.79914\n",
      "Epoch 176/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5109e-05 - accuracy: 1.0000 - val_loss: 2.5535 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.79914\n",
      "Epoch 177/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6875e-04 - accuracy: 1.0000 - val_loss: 2.4902 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.79914\n",
      "Epoch 178/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.7451e-05 - accuracy: 1.0000 - val_loss: 2.4820 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.79914\n",
      "Epoch 179/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.9218e-06 - accuracy: 1.0000 - val_loss: 2.4746 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.79914\n",
      "Epoch 180/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.9536e-05 - accuracy: 1.0000 - val_loss: 2.4783 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.79914\n",
      "Epoch 181/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.9505e-06 - accuracy: 1.0000 - val_loss: 2.4830 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.79914\n",
      "Epoch 182/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4889e-05 - accuracy: 1.0000 - val_loss: 2.4824 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.79914\n",
      "Epoch 183/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3063e-04 - accuracy: 1.0000 - val_loss: 2.4321 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.79914\n",
      "Epoch 184/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.8928e-05 - accuracy: 1.0000 - val_loss: 2.4544 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.79914\n",
      "Epoch 185/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 6.4148e-05 - accuracy: 1.0000 - val_loss: 2.4355 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.79914\n",
      "Epoch 186/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3117e-05 - accuracy: 1.0000 - val_loss: 2.4463 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.79914\n",
      "Epoch 187/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.0427e-05 - accuracy: 1.0000 - val_loss: 2.4578 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.79914\n",
      "Epoch 188/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.7927e-05 - accuracy: 1.0000 - val_loss: 2.4559 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.79914\n",
      "Epoch 189/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3022e-04 - accuracy: 1.0000 - val_loss: 2.4684 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.79914\n",
      "Epoch 190/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.0551e-04 - accuracy: 1.0000 - val_loss: 2.4493 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.79914\n",
      "Epoch 191/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2598e-05 - accuracy: 1.0000 - val_loss: 2.4588 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.79914\n",
      "Epoch 192/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2042e-05 - accuracy: 1.0000 - val_loss: 2.4731 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.79914\n",
      "Epoch 193/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7671e-05 - accuracy: 1.0000 - val_loss: 2.4756 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.79914\n",
      "Epoch 194/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.6332e-06 - accuracy: 1.0000 - val_loss: 2.4904 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.79914\n",
      "Epoch 195/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.3065e-06 - accuracy: 1.0000 - val_loss: 2.5041 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.79914\n",
      "Epoch 196/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7396e-05 - accuracy: 1.0000 - val_loss: 2.4823 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.79914\n",
      "Epoch 197/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.2064e-06 - accuracy: 1.0000 - val_loss: 2.4974 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.79914\n",
      "Epoch 198/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.0004e-05 - accuracy: 1.0000 - val_loss: 2.4987 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.79914\n",
      "Epoch 199/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.7863e-05 - accuracy: 1.0000 - val_loss: 2.4996 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1.79914\n",
      "Epoch 200/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.4958 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.79914\n",
      "Epoch 201/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.6984e-04 - accuracy: 1.0000 - val_loss: 2.3451 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1.79914\n",
      "Epoch 202/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.6888e-04 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.7007\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1.79914\n",
      "Epoch 203/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.4634e-04 - accuracy: 1.0000 - val_loss: 2.0749 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.79914\n",
      "Epoch 204/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3722e-05 - accuracy: 1.0000 - val_loss: 2.0155 - val_accuracy: 0.7483\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.79914\n",
      "Epoch 205/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7608e-05 - accuracy: 1.0000 - val_loss: 2.0104 - val_accuracy: 0.7483\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1.79914\n",
      "Epoch 206/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.1895e-05 - accuracy: 1.0000 - val_loss: 2.0244 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.79914\n",
      "Epoch 207/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8795e-05 - accuracy: 1.0000 - val_loss: 2.0438 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1.79914\n",
      "Epoch 208/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.7118e-05 - accuracy: 1.0000 - val_loss: 2.0449 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.79914\n",
      "Epoch 209/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5596e-05 - accuracy: 1.0000 - val_loss: 2.0484 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.79914\n",
      "Epoch 210/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1323e-05 - accuracy: 1.0000 - val_loss: 2.0660 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.79914\n",
      "Epoch 211/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3138e-04 - accuracy: 1.0000 - val_loss: 2.0566 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.79914\n",
      "Epoch 212/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2287e-05 - accuracy: 1.0000 - val_loss: 2.0664 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1.79914\n",
      "Epoch 213/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9850e-05 - accuracy: 1.0000 - val_loss: 2.0786 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1.79914\n",
      "Epoch 214/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.6508e-05 - accuracy: 1.0000 - val_loss: 2.0809 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1.79914\n",
      "Epoch 215/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8906e-06 - accuracy: 1.0000 - val_loss: 2.0872 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.79914\n",
      "Epoch 216/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.0863e-05 - accuracy: 1.0000 - val_loss: 2.0972 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1.79914\n",
      "Epoch 217/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4555e-04 - accuracy: 1.0000 - val_loss: 2.1390 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1.79914\n",
      "Epoch 218/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0019 - accuracy: 0.9983 - val_loss: 2.7355 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1.79914\n",
      "Epoch 219/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9085e-06 - accuracy: 1.0000 - val_loss: 2.7630 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.79914\n",
      "Epoch 220/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6051e-05 - accuracy: 1.0000 - val_loss: 2.7170 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1.79914\n",
      "Epoch 221/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1201e-05 - accuracy: 1.0000 - val_loss: 2.6691 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1.79914\n",
      "Epoch 222/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.6239e-05 - accuracy: 1.0000 - val_loss: 2.6076 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1.79914\n",
      "Epoch 223/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3737e-05 - accuracy: 1.0000 - val_loss: 2.5909 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1.79914\n",
      "Epoch 224/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3104e-05 - accuracy: 1.0000 - val_loss: 2.5869 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1.79914\n",
      "Epoch 225/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1014e-05 - accuracy: 1.0000 - val_loss: 2.5754 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1.79914\n",
      "Epoch 226/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.9654e-06 - accuracy: 1.0000 - val_loss: 2.5477 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1.79914\n",
      "Epoch 227/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.0765e-04 - accuracy: 1.0000 - val_loss: 2.5400 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1.79914\n",
      "Epoch 228/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.7547e-05 - accuracy: 1.0000 - val_loss: 2.5494 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1.79914\n",
      "Epoch 229/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.2375e-05 - accuracy: 1.0000 - val_loss: 2.5256 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1.79914\n",
      "Epoch 230/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.9263e-06 - accuracy: 1.0000 - val_loss: 2.5153 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1.79914\n",
      "Epoch 231/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.1835e-05 - accuracy: 1.0000 - val_loss: 2.5041 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1.79914\n",
      "Epoch 232/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3967e-05 - accuracy: 1.0000 - val_loss: 2.4964 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1.79914\n",
      "Epoch 233/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.0623e-04 - accuracy: 1.0000 - val_loss: 2.5399 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1.79914\n",
      "Epoch 234/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.2512e-06 - accuracy: 1.0000 - val_loss: 2.9451 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1.79914\n",
      "Epoch 235/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5998e-05 - accuracy: 1.0000 - val_loss: 2.9694 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1.79914\n",
      "Epoch 236/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3407e-05 - accuracy: 1.0000 - val_loss: 2.9319 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1.79914\n",
      "Epoch 237/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9360e-06 - accuracy: 1.0000 - val_loss: 2.9031 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1.79914\n",
      "Epoch 238/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0667e-05 - accuracy: 1.0000 - val_loss: 2.8959 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1.79914\n",
      "Epoch 239/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.1113e-06 - accuracy: 1.0000 - val_loss: 2.8835 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1.79914\n",
      "Epoch 240/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 8.5568e-06 - accuracy: 1.0000 - val_loss: 2.8908 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1.79914\n",
      "Epoch 241/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0266e-05 - accuracy: 1.0000 - val_loss: 2.8737 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1.79914\n",
      "Epoch 242/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.2793e-05 - accuracy: 1.0000 - val_loss: 2.8760 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1.79914\n",
      "Epoch 243/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4435e-05 - accuracy: 1.0000 - val_loss: 2.8389 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1.79914\n",
      "Epoch 244/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.6548e-05 - accuracy: 1.0000 - val_loss: 2.8309 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1.79914\n",
      "Epoch 245/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 3.0047 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1.79914\n",
      "Epoch 246/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3295e-05 - accuracy: 1.0000 - val_loss: 4.6801 - val_accuracy: 0.4490\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1.79914\n",
      "Epoch 247/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2212 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1.79914\n",
      "Epoch 248/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 6.0102e-05 - accuracy: 1.0000 - val_loss: 3.7736 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1.79914\n",
      "Epoch 249/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9865e-05 - accuracy: 1.0000 - val_loss: 3.5716 - val_accuracy: 0.5442\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1.79914\n",
      "Epoch 250/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.8996e-04 - accuracy: 1.0000 - val_loss: 3.4802 - val_accuracy: 0.5442\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1.79914\n",
      "Epoch 251/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6575e-04 - accuracy: 1.0000 - val_loss: 3.3295 - val_accuracy: 0.5510\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1.79914\n",
      "Epoch 252/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.4178e-04 - accuracy: 1.0000 - val_loss: 3.1958 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1.79914\n",
      "Epoch 253/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.3894e-04 - accuracy: 1.0000 - val_loss: 3.1787 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1.79914\n",
      "Epoch 254/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.2024e-05 - accuracy: 1.0000 - val_loss: 3.1359 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1.79914\n",
      "Epoch 255/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.4352e-05 - accuracy: 1.0000 - val_loss: 3.1041 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1.79914\n",
      "Epoch 256/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.7752e-05 - accuracy: 1.0000 - val_loss: 3.0990 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1.79914\n",
      "Epoch 257/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 9.1428e-05 - accuracy: 1.0000 - val_loss: 3.0927 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1.79914\n",
      "Epoch 258/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.5782\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1.79914\n",
      "Epoch 259/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.6185e-05 - accuracy: 1.0000 - val_loss: 2.6094 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1.79914\n",
      "Epoch 260/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 3.4404 - val_accuracy: 0.5034\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1.79914\n",
      "Epoch 261/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.2836e-05 - accuracy: 1.0000 - val_loss: 3.5847 - val_accuracy: 0.4966\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1.79914\n",
      "Epoch 262/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.1620 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.79914\n",
      "Epoch 263/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.0379e-05 - accuracy: 1.0000 - val_loss: 2.9286 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1.79914\n",
      "Epoch 264/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0971e-04 - accuracy: 1.0000 - val_loss: 2.8547 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1.79914\n",
      "Epoch 265/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.5434e-05 - accuracy: 1.0000 - val_loss: 2.8153 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1.79914\n",
      "Epoch 266/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.8216e-06 - accuracy: 1.0000 - val_loss: 2.8069 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1.79914\n",
      "Epoch 267/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5160e-04 - accuracy: 1.0000 - val_loss: 2.7863 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1.79914\n",
      "Epoch 268/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.6834e-05 - accuracy: 1.0000 - val_loss: 2.7314 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1.79914\n",
      "Epoch 269/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7810e-05 - accuracy: 1.0000 - val_loss: 2.7251 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1.79914\n",
      "Epoch 270/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7060 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1.79914\n",
      "Epoch 271/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1140e-04 - accuracy: 1.0000 - val_loss: 2.4050 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1.79914\n",
      "Epoch 272/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 5.5883e-05 - accuracy: 1.0000 - val_loss: 2.3665 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1.79914\n",
      "Epoch 273/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.8656e-05 - accuracy: 1.0000 - val_loss: 2.3957 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1.79914\n",
      "Epoch 274/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.6297e-05 - accuracy: 1.0000 - val_loss: 2.4208 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1.79914\n",
      "Epoch 275/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.8189e-05 - accuracy: 1.0000 - val_loss: 2.4406 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 1.79914\n",
      "Epoch 276/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.1387e-04 - accuracy: 1.0000 - val_loss: 2.5381 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1.79914\n",
      "Epoch 277/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4024e-05 - accuracy: 1.0000 - val_loss: 2.5698 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1.79914\n",
      "Epoch 278/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2556e-05 - accuracy: 1.0000 - val_loss: 2.5704 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 1.79914\n",
      "Epoch 279/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2882 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1.79914\n",
      "Epoch 280/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0015 - accuracy: 0.9983 - val_loss: 2.4207 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1.79914\n",
      "Epoch 281/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.7121e-06 - accuracy: 1.0000 - val_loss: 2.5549 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 1.79914\n",
      "Epoch 282/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.0571e-05 - accuracy: 1.0000 - val_loss: 2.7121 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1.79914\n",
      "Epoch 283/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 2.8084 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1.79914\n",
      "Epoch 284/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.5112e-05 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1.79914\n",
      "Epoch 285/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.7971e-05 - accuracy: 1.0000 - val_loss: 2.6981 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1.79914\n",
      "Epoch 286/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 2.3620 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1.79914\n",
      "Epoch 287/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1882e-04 - accuracy: 1.0000 - val_loss: 2.3402 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1.79914\n",
      "Epoch 288/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.5774e-04 - accuracy: 1.0000 - val_loss: 2.4821 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1.79914\n",
      "Epoch 289/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9716e-04 - accuracy: 1.0000 - val_loss: 2.6274 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1.79914\n",
      "Epoch 290/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 8.6910e-04 - accuracy: 1.0000 - val_loss: 2.5899 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1.79914\n",
      "Epoch 291/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.0764e-05 - accuracy: 1.0000 - val_loss: 2.4466 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1.79914\n",
      "Epoch 292/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.3474e-04 - accuracy: 1.0000 - val_loss: 2.4500 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 1.79914\n",
      "Epoch 293/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.8985 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 1.79914\n",
      "Epoch 294/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 2.0067e-05 - accuracy: 1.0000 - val_loss: 2.9703 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 1.79914\n",
      "Epoch 295/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 1.5147e-04 - accuracy: 1.0000 - val_loss: 2.9811 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1.79914\n",
      "Epoch 296/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 7.0373e-04 - accuracy: 1.0000 - val_loss: 2.9104 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 1.79914\n",
      "Epoch 297/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0408e-05 - accuracy: 1.0000 - val_loss: 2.7172 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 1.79914\n",
      "Epoch 298/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 3.2327e-05 - accuracy: 1.0000 - val_loss: 2.6483 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1.79914\n",
      "Epoch 299/300\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 4.3335e-05 - accuracy: 1.0000 - val_loss: 2.6289 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1.79914\n",
      "Epoch 300/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7774e-05 - accuracy: 1.0000 - val_loss: 2.6033 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1.79914\n",
      "predict test data\n",
      "183/183 [==============================] - 11s 60ms/step\n",
      "../npy/3\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "(732, 256, 256, 3)\n",
      "(732, 1)\n",
      "../npy/3\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(183, 256, 256, 3)\n",
      "(183, 1)\n",
      "(732, 1)\n",
      "(183, 1)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 2 0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 2 0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 2 0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 5 0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 5 0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 5 0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 5 0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 1 0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 1 0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 1 0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 1 0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 1 0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 1 0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 2 0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 2 0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            4098        global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/300\n",
      "585/585 [==============================] - 23s 39ms/step - loss: 0.7541 - accuracy: 0.7214 - val_loss: 5.6631 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.66308, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 2/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.3043 - accuracy: 0.8821 - val_loss: 10.0459 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 5.66308\n",
      "Epoch 3/300\n",
      "585/585 [==============================] - 3s 5ms/step - loss: 0.1479 - accuracy: 0.9402 - val_loss: 7.0600 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 5.66308\n",
      "Epoch 4/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0738 - accuracy: 0.9726 - val_loss: 7.7871 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 5.66308\n",
      "Epoch 5/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0583 - accuracy: 0.9812 - val_loss: 9.8464 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 5.66308\n",
      "Epoch 6/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0531 - accuracy: 0.9846 - val_loss: 10.3974 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 5.66308\n",
      "Epoch 7/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 11.2384 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.66308\n",
      "Epoch 8/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0218 - accuracy: 0.9897 - val_loss: 10.3538 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.66308\n",
      "Epoch 9/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 10.5509 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5.66308\n",
      "Epoch 10/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1060 - accuracy: 0.9624 - val_loss: 5.4415 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.66308 to 5.44147, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 11/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0893 - accuracy: 0.9692 - val_loss: 3.6551 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 5.44147 to 3.65513, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 12/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0940 - accuracy: 0.9675 - val_loss: 3.8896 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.65513\n",
      "Epoch 13/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1439 - accuracy: 0.9607 - val_loss: 5.9469 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.65513\n",
      "Epoch 14/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1115 - accuracy: 0.9607 - val_loss: 6.4991 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.65513\n",
      "Epoch 15/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0813 - accuracy: 0.9744 - val_loss: 6.7070 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.65513\n",
      "Epoch 16/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0705 - accuracy: 0.9744 - val_loss: 6.0706 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.65513\n",
      "Epoch 17/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1029 - accuracy: 0.9573 - val_loss: 7.3302 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.65513\n",
      "Epoch 18/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0935 - accuracy: 0.9607 - val_loss: 7.5769 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.65513\n",
      "Epoch 19/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0896 - accuracy: 0.9709 - val_loss: 10.1701 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.65513\n",
      "Epoch 20/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0780 - accuracy: 0.9658 - val_loss: 8.3245 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.65513\n",
      "Epoch 21/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 8.0075 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.65513\n",
      "Epoch 22/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0633 - accuracy: 0.9778 - val_loss: 7.6151 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.65513\n",
      "Epoch 23/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0387 - accuracy: 0.9880 - val_loss: 8.1290 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.65513\n",
      "Epoch 24/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 7.5959 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.65513\n",
      "Epoch 25/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 7.7066 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.65513\n",
      "Epoch 26/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0079 - accuracy: 0.9966 - val_loss: 7.4697 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.65513\n",
      "Epoch 27/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 6.4972 - val_accuracy: 0.0068\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.65513\n",
      "Epoch 28/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 6.5250 - val_accuracy: 0.0136\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.65513\n",
      "Epoch 29/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 6.7179 - val_accuracy: 0.0136\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.65513\n",
      "Epoch 30/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 8.1789 - val_accuracy: 0.0272\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.65513\n",
      "Epoch 31/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0861 - accuracy: 0.9795 - val_loss: 4.4892 - val_accuracy: 0.2789\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.65513\n",
      "Epoch 32/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0390 - accuracy: 0.9863 - val_loss: 6.3983 - val_accuracy: 0.0476\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.65513\n",
      "Epoch 33/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0330 - accuracy: 0.9880 - val_loss: 8.7879 - val_accuracy: 0.0612\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.65513\n",
      "Epoch 34/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0376 - accuracy: 0.9915 - val_loss: 6.8003 - val_accuracy: 0.1293\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.65513\n",
      "Epoch 35/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 5.2756 - val_accuracy: 0.1293\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.65513\n",
      "Epoch 36/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 3.4298 - val_accuracy: 0.3946\n",
      "\n",
      "Epoch 00036: val_loss improved from 3.65513 to 3.42978, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 37/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 3.5426 - val_accuracy: 0.4014\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.42978\n",
      "Epoch 38/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 3.6024 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.42978\n",
      "Epoch 39/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 3.9436 - val_accuracy: 0.4082\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.42978\n",
      "Epoch 40/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8224e-04 - accuracy: 1.0000 - val_loss: 3.8033 - val_accuracy: 0.4218\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.42978\n",
      "Epoch 41/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.2485e-04 - accuracy: 1.0000 - val_loss: 3.6657 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.42978\n",
      "Epoch 42/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1887 - val_accuracy: 0.4966\n",
      "\n",
      "Epoch 00042: val_loss improved from 3.42978 to 3.18867, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 43/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1924e-04 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00043: val_loss improved from 3.18867 to 2.61973, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 44/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5453 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.61973 to 2.54533, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 45/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8274e-04 - accuracy: 1.0000 - val_loss: 2.5825 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.54533\n",
      "Epoch 46/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 3.0985 - val_accuracy: 0.5170\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.54533\n",
      "Epoch 47/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0220 - accuracy: 0.9966 - val_loss: 4.7429 - val_accuracy: 0.3878\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.54533\n",
      "Epoch 48/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 2.3313 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.54533 to 2.33126, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 49/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 1.7111 - val_accuracy: 0.7551\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.33126 to 1.71113, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 50/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0240 - accuracy: 0.9880 - val_loss: 2.0181 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.71113\n",
      "Epoch 51/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0118 - accuracy: 0.9932 - val_loss: 4.5100 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.71113\n",
      "Epoch 52/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0283 - accuracy: 0.9897 - val_loss: 1.4877 - val_accuracy: 0.7755\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.71113 to 1.48773, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 53/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 1.2712 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.48773 to 1.27121, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 54/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0702 - accuracy: 0.9829 - val_loss: 3.4048 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.27121\n",
      "Epoch 55/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0935 - accuracy: 0.9709 - val_loss: 2.6681 - val_accuracy: 0.5510\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.27121\n",
      "Epoch 56/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0674 - accuracy: 0.9812 - val_loss: 0.8254 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.27121 to 0.82542, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 57/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.6817 - val_accuracy: 0.8163\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.82542 to 0.68170, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 58/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.7230 - val_accuracy: 0.8980\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.68170\n",
      "Epoch 59/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0395 - accuracy: 0.9880 - val_loss: 0.8374 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.68170\n",
      "Epoch 60/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 1.0837 - val_accuracy: 0.7755\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.68170\n",
      "Epoch 61/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 2.3646 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.68170\n",
      "Epoch 62/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 4.0216 - val_accuracy: 0.4898\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.68170\n",
      "Epoch 63/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 1.9367 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.68170\n",
      "Epoch 64/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0193 - accuracy: 0.9915 - val_loss: 5.5850 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.68170\n",
      "Epoch 65/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 6.7621 - val_accuracy: 0.2517\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.68170\n",
      "Epoch 66/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 2.5031 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.68170\n",
      "Epoch 67/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 2.3223 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.68170\n",
      "Epoch 68/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0845 - accuracy: 0.9744 - val_loss: 3.2991 - val_accuracy: 0.4966\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.68170\n",
      "Epoch 69/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0144 - accuracy: 0.9932 - val_loss: 2.4841 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.68170\n",
      "Epoch 70/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 2.8479 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.68170\n",
      "Epoch 71/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 5.0508 - val_accuracy: 0.4082\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.68170\n",
      "Epoch 72/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0181 - accuracy: 0.9897 - val_loss: 3.5215 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.68170\n",
      "Epoch 73/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2028 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.68170\n",
      "Epoch 74/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 3.0067 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.68170\n",
      "Epoch 75/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6773 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.68170\n",
      "Epoch 76/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4237 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.68170\n",
      "Epoch 77/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4203 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.68170\n",
      "Epoch 78/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.8469e-04 - accuracy: 1.0000 - val_loss: 2.4273 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.68170\n",
      "Epoch 79/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.6236e-04 - accuracy: 1.0000 - val_loss: 2.2868 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.68170\n",
      "Epoch 80/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1205e-04 - accuracy: 1.0000 - val_loss: 2.1789 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.68170\n",
      "Epoch 81/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9694e-04 - accuracy: 1.0000 - val_loss: 2.1595 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.68170\n",
      "Epoch 82/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.7485e-04 - accuracy: 1.0000 - val_loss: 2.1171 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.68170\n",
      "Epoch 83/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7067e-04 - accuracy: 1.0000 - val_loss: 2.0846 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.68170\n",
      "Epoch 84/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.4867 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.68170\n",
      "Epoch 85/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0051 - accuracy: 0.9966 - val_loss: 3.5174 - val_accuracy: 0.5306\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.68170\n",
      "Epoch 86/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.8674e-04 - accuracy: 1.0000 - val_loss: 2.5795 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.68170\n",
      "Epoch 87/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2380 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.68170\n",
      "Epoch 88/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.6402e-04 - accuracy: 1.0000 - val_loss: 2.4601 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.68170\n",
      "Epoch 89/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.9097 - val_accuracy: 0.8027\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.68170\n",
      "Epoch 90/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 1.7929 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.68170\n",
      "Epoch 91/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 1.7338 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.68170\n",
      "Epoch 92/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 2.8630 - val_accuracy: 0.5306\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.68170\n",
      "Epoch 93/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 1.7128 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.68170\n",
      "Epoch 94/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0614 - accuracy: 0.9897 - val_loss: 2.8119 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.68170\n",
      "Epoch 95/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 1.8818 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.68170\n",
      "Epoch 96/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.6056 - val_accuracy: 0.9320\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.68170 to 0.60563, saving model to model_normalize_best(cv3).h5\n",
      "Epoch 97/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0655 - accuracy: 0.9778 - val_loss: 2.8427 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.60563\n",
      "Epoch 98/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0461 - accuracy: 0.9778 - val_loss: 3.2159 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.60563\n",
      "Epoch 99/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9949 - val_loss: 2.8791 - val_accuracy: 0.6395\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.60563\n",
      "Epoch 100/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 2.5994 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.60563\n",
      "Epoch 101/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 1.4425 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.60563\n",
      "Epoch 102/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.8542e-04 - accuracy: 1.0000 - val_loss: 1.4977 - val_accuracy: 0.7279\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.60563\n",
      "Epoch 103/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.8839e-04 - accuracy: 1.0000 - val_loss: 1.6353 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.60563\n",
      "Epoch 104/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0864e-04 - accuracy: 1.0000 - val_loss: 1.6989 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.60563\n",
      "Epoch 105/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9375e-04 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.60563\n",
      "Epoch 106/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.7472e-04 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.60563\n",
      "Epoch 107/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.6073e-04 - accuracy: 1.0000 - val_loss: 1.8902 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.60563\n",
      "Epoch 108/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3871e-04 - accuracy: 1.0000 - val_loss: 1.9342 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.60563\n",
      "Epoch 109/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 1.9756 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.60563\n",
      "Epoch 110/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 1.8577 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.60563\n",
      "Epoch 111/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 2.1193 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.60563\n",
      "Epoch 112/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.2226 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.60563\n",
      "Epoch 113/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8983e-04 - accuracy: 1.0000 - val_loss: 2.2217 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.60563\n",
      "Epoch 114/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.2965e-04 - accuracy: 1.0000 - val_loss: 2.2258 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.60563\n",
      "Epoch 115/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8718e-04 - accuracy: 1.0000 - val_loss: 2.2321 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.60563\n",
      "Epoch 116/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0458e-04 - accuracy: 1.0000 - val_loss: 2.2371 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.60563\n",
      "Epoch 117/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2219e-04 - accuracy: 1.0000 - val_loss: 2.2636 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.60563\n",
      "Epoch 118/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3599e-04 - accuracy: 1.0000 - val_loss: 2.2977 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.60563\n",
      "Epoch 119/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.8792e-05 - accuracy: 1.0000 - val_loss: 2.2769 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.60563\n",
      "Epoch 120/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3528 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.60563\n",
      "Epoch 121/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5327e-04 - accuracy: 1.0000 - val_loss: 2.3885 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.60563\n",
      "Epoch 122/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.3847 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.60563\n",
      "Epoch 123/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3924 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.60563\n",
      "Epoch 124/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4777e-04 - accuracy: 1.0000 - val_loss: 2.3719 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.60563\n",
      "Epoch 125/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4618e-04 - accuracy: 1.0000 - val_loss: 2.3845 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.60563\n",
      "Epoch 126/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7721e-04 - accuracy: 1.0000 - val_loss: 2.3668 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.60563\n",
      "Epoch 127/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8715e-04 - accuracy: 1.0000 - val_loss: 2.3671 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.60563\n",
      "Epoch 128/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6897e-04 - accuracy: 1.0000 - val_loss: 2.3860 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.60563\n",
      "Epoch 129/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.1425e-05 - accuracy: 1.0000 - val_loss: 2.3775 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.60563\n",
      "Epoch 130/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.2172e-04 - accuracy: 1.0000 - val_loss: 2.3839 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.60563\n",
      "Epoch 131/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.0988e-04 - accuracy: 1.0000 - val_loss: 2.3860 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.60563\n",
      "Epoch 132/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8161e-04 - accuracy: 1.0000 - val_loss: 2.3688 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.60563\n",
      "Epoch 133/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4177e-04 - accuracy: 1.0000 - val_loss: 2.3594 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.60563\n",
      "Epoch 134/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.7827e-05 - accuracy: 1.0000 - val_loss: 2.3436 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.60563\n",
      "Epoch 135/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0601e-04 - accuracy: 1.0000 - val_loss: 2.3401 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.60563\n",
      "Epoch 136/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.6326e-05 - accuracy: 1.0000 - val_loss: 2.3346 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.60563\n",
      "Epoch 137/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.2169e-05 - accuracy: 1.0000 - val_loss: 2.3340 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.60563\n",
      "Epoch 138/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3162e-04 - accuracy: 1.0000 - val_loss: 2.3411 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.60563\n",
      "Epoch 139/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0062 - accuracy: 0.9966 - val_loss: 2.5518 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.60563\n",
      "Epoch 140/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9448e-04 - accuracy: 1.0000 - val_loss: 2.6121 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.60563\n",
      "Epoch 141/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6089e-04 - accuracy: 1.0000 - val_loss: 2.5946 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.60563\n",
      "Epoch 142/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.6147e-04 - accuracy: 1.0000 - val_loss: 2.5857 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.60563\n",
      "Epoch 143/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1757e-04 - accuracy: 1.0000 - val_loss: 2.5730 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.60563\n",
      "Epoch 144/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3855e-04 - accuracy: 1.0000 - val_loss: 2.5517 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.60563\n",
      "Epoch 145/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2993e-04 - accuracy: 1.0000 - val_loss: 2.5627 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.60563\n",
      "Epoch 146/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.7236e-04 - accuracy: 1.0000 - val_loss: 2.5463 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.60563\n",
      "Epoch 147/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.7880e-05 - accuracy: 1.0000 - val_loss: 2.5278 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.60563\n",
      "Epoch 148/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0821e-04 - accuracy: 1.0000 - val_loss: 2.5225 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.60563\n",
      "Epoch 149/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7185e-05 - accuracy: 1.0000 - val_loss: 2.5289 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.60563\n",
      "Epoch 150/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3802e-05 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.60563\n",
      "Epoch 151/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.8219e-05 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.60563\n",
      "Epoch 152/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.2235e-05 - accuracy: 1.0000 - val_loss: 2.5367 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.60563\n",
      "Epoch 153/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4505e-04 - accuracy: 1.0000 - val_loss: 2.5226 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.60563\n",
      "Epoch 154/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8235e-04 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.60563\n",
      "Epoch 155/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.6743e-05 - accuracy: 1.0000 - val_loss: 2.5091 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.60563\n",
      "Epoch 156/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.2917e-05 - accuracy: 1.0000 - val_loss: 2.4887 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.60563\n",
      "Epoch 157/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.8044e-05 - accuracy: 1.0000 - val_loss: 2.4943 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.60563\n",
      "Epoch 158/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4576e-04 - accuracy: 1.0000 - val_loss: 2.5014 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.60563\n",
      "Epoch 159/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4679 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.60563\n",
      "Epoch 160/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.4238e-04 - accuracy: 1.0000 - val_loss: 2.4389 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.60563\n",
      "Epoch 161/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.4665e-05 - accuracy: 1.0000 - val_loss: 2.4267 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.60563\n",
      "Epoch 162/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.7834e-05 - accuracy: 1.0000 - val_loss: 2.4424 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.60563\n",
      "Epoch 163/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4706e-04 - accuracy: 1.0000 - val_loss: 2.3985 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.60563\n",
      "Epoch 164/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 2.3636 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.60563\n",
      "Epoch 165/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.5563e-04 - accuracy: 1.0000 - val_loss: 1.9615 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.60563\n",
      "Epoch 166/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9875e-04 - accuracy: 1.0000 - val_loss: 1.9110 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.60563\n",
      "Epoch 167/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7646e-04 - accuracy: 1.0000 - val_loss: 1.9424 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.60563\n",
      "Epoch 168/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.3403e-04 - accuracy: 1.0000 - val_loss: 2.0147 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.60563\n",
      "Epoch 169/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.7017e-05 - accuracy: 1.0000 - val_loss: 2.0747 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.60563\n",
      "Epoch 170/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2904e-04 - accuracy: 1.0000 - val_loss: 2.0886 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.60563\n",
      "Epoch 171/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5909e-05 - accuracy: 1.0000 - val_loss: 2.1011 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.60563\n",
      "Epoch 172/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0082e-04 - accuracy: 1.0000 - val_loss: 2.1181 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.60563\n",
      "Epoch 173/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.5788e-05 - accuracy: 1.0000 - val_loss: 2.1380 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.60563\n",
      "Epoch 174/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.6382e-05 - accuracy: 1.0000 - val_loss: 2.1231 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.60563\n",
      "Epoch 175/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.5336e-05 - accuracy: 1.0000 - val_loss: 2.1264 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.60563\n",
      "Epoch 176/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.4935e-05 - accuracy: 1.0000 - val_loss: 2.1409 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.60563\n",
      "Epoch 177/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8248e-04 - accuracy: 1.0000 - val_loss: 2.1557 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.60563\n",
      "Epoch 178/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.6908e-05 - accuracy: 1.0000 - val_loss: 2.1650 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.60563\n",
      "Epoch 179/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.8389e-04 - accuracy: 1.0000 - val_loss: 2.1738 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.60563\n",
      "Epoch 180/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3241e-04 - accuracy: 1.0000 - val_loss: 2.2155 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.60563\n",
      "Epoch 181/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.4967e-04 - accuracy: 1.0000 - val_loss: 2.2469 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.60563\n",
      "Epoch 182/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.1620e-05 - accuracy: 1.0000 - val_loss: 2.4200 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.60563\n",
      "Epoch 183/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.0679e-04 - accuracy: 1.0000 - val_loss: 2.4635 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.60563\n",
      "Epoch 184/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.9220e-05 - accuracy: 1.0000 - val_loss: 2.4290 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.60563\n",
      "Epoch 185/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.4336e-05 - accuracy: 1.0000 - val_loss: 2.4038 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.60563\n",
      "Epoch 186/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.9547e-05 - accuracy: 1.0000 - val_loss: 2.3976 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.60563\n",
      "Epoch 187/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 2.4345 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.60563\n",
      "Epoch 188/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5797e-04 - accuracy: 1.0000 - val_loss: 3.0206 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.60563\n",
      "Epoch 189/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9471 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.60563\n",
      "Epoch 190/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.0053e-04 - accuracy: 1.0000 - val_loss: 2.7907 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.60563\n",
      "Epoch 191/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.3140e-05 - accuracy: 1.0000 - val_loss: 2.7428 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.60563\n",
      "Epoch 192/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4355e-04 - accuracy: 1.0000 - val_loss: 2.7100 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.60563\n",
      "Epoch 193/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4350e-04 - accuracy: 1.0000 - val_loss: 2.7023 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.60563\n",
      "Epoch 194/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3476e-04 - accuracy: 1.0000 - val_loss: 2.6801 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.60563\n",
      "Epoch 195/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6195 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.60563\n",
      "Epoch 196/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3154e-04 - accuracy: 1.0000 - val_loss: 2.5388 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.60563\n",
      "Epoch 197/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.9669e-05 - accuracy: 1.0000 - val_loss: 2.5074 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.60563\n",
      "Epoch 198/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9918e-04 - accuracy: 1.0000 - val_loss: 2.5183 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.60563\n",
      "Epoch 199/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1241e-04 - accuracy: 1.0000 - val_loss: 2.5201 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.60563\n",
      "Epoch 200/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.8896e-04 - accuracy: 1.0000 - val_loss: 2.5340 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.60563\n",
      "Epoch 201/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 2.5420 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.60563\n",
      "Epoch 202/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.3520e-05 - accuracy: 1.0000 - val_loss: 2.5575 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.60563\n",
      "Epoch 203/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7433e-04 - accuracy: 1.0000 - val_loss: 2.5611 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.60563\n",
      "Epoch 204/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5465e-04 - accuracy: 1.0000 - val_loss: 2.5704 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.60563\n",
      "Epoch 205/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.8736e-05 - accuracy: 1.0000 - val_loss: 2.5559 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.60563\n",
      "Epoch 206/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5407e-05 - accuracy: 1.0000 - val_loss: 2.5513 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.60563\n",
      "Epoch 207/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5976e-04 - accuracy: 1.0000 - val_loss: 2.5454 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.60563\n",
      "Epoch 208/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9357e-04 - accuracy: 1.0000 - val_loss: 2.5651 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.60563\n",
      "Epoch 209/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.4428e-04 - accuracy: 1.0000 - val_loss: 2.5622 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.60563\n",
      "Epoch 210/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9869e-04 - accuracy: 1.0000 - val_loss: 2.5672 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.60563\n",
      "Epoch 211/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.3203e-05 - accuracy: 1.0000 - val_loss: 2.5481 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.60563\n",
      "Epoch 212/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3298e-04 - accuracy: 1.0000 - val_loss: 2.5603 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.60563\n",
      "Epoch 213/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.9796e-05 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.60563\n",
      "Epoch 214/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9731e-04 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.60563\n",
      "Epoch 215/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.3814e-05 - accuracy: 1.0000 - val_loss: 2.5384 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.60563\n",
      "Epoch 216/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1733e-05 - accuracy: 1.0000 - val_loss: 2.5241 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.60563\n",
      "Epoch 217/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2000e-04 - accuracy: 1.0000 - val_loss: 2.5180 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.60563\n",
      "Epoch 218/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1003e-04 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.60563\n",
      "Epoch 219/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4141e-04 - accuracy: 1.0000 - val_loss: 2.5277 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.60563\n",
      "Epoch 220/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2405e-04 - accuracy: 1.0000 - val_loss: 2.5164 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.60563\n",
      "Epoch 221/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.8835e-05 - accuracy: 1.0000 - val_loss: 2.5089 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.60563\n",
      "Epoch 222/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1111e-05 - accuracy: 1.0000 - val_loss: 2.4993 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.60563\n",
      "Epoch 223/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0675e-04 - accuracy: 1.0000 - val_loss: 2.4880 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.60563\n",
      "Epoch 224/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.1130e-05 - accuracy: 1.0000 - val_loss: 2.4775 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.60563\n",
      "Epoch 225/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9920e-04 - accuracy: 1.0000 - val_loss: 2.4893 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.60563\n",
      "Epoch 226/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4356e-04 - accuracy: 1.0000 - val_loss: 2.4924 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.60563\n",
      "Epoch 227/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.0296e-05 - accuracy: 1.0000 - val_loss: 2.4972 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.60563\n",
      "Epoch 228/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2516e-04 - accuracy: 1.0000 - val_loss: 2.4746 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.60563\n",
      "Epoch 229/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4605 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.60563\n",
      "Epoch 230/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3852e-04 - accuracy: 1.0000 - val_loss: 2.2548 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.60563\n",
      "Epoch 231/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.0131e-05 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.60563\n",
      "Epoch 232/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.7736e-05 - accuracy: 1.0000 - val_loss: 2.2159 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.60563\n",
      "Epoch 233/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.7150e-05 - accuracy: 1.0000 - val_loss: 2.2306 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.60563\n",
      "Epoch 234/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1595e-04 - accuracy: 1.0000 - val_loss: 2.2285 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.60563\n",
      "Epoch 235/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.1921e-04 - accuracy: 1.0000 - val_loss: 2.2405 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.60563\n",
      "Epoch 236/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9900e-05 - accuracy: 1.0000 - val_loss: 2.2295 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.60563\n",
      "Epoch 237/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2533e-05 - accuracy: 1.0000 - val_loss: 2.2037 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.60563\n",
      "Epoch 238/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.2635 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.60563\n",
      "Epoch 239/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.9136e-05 - accuracy: 1.0000 - val_loss: 2.6003 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.60563\n",
      "Epoch 240/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.8081e-05 - accuracy: 1.0000 - val_loss: 2.6111 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.60563\n",
      "Epoch 241/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.9406e-05 - accuracy: 1.0000 - val_loss: 2.5756 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.60563\n",
      "Epoch 242/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.0388e-05 - accuracy: 1.0000 - val_loss: 2.5373 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.60563\n",
      "Epoch 243/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1187e-05 - accuracy: 1.0000 - val_loss: 2.5127 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.60563\n",
      "Epoch 244/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 9.8437e-05 - accuracy: 1.0000 - val_loss: 2.5140 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.60563\n",
      "Epoch 245/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9129e-04 - accuracy: 1.0000 - val_loss: 2.5097 - val_accuracy: 0.6531\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.60563\n",
      "Epoch 246/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.2056e-05 - accuracy: 1.0000 - val_loss: 2.4760 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.60563\n",
      "Epoch 247/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.4334e-05 - accuracy: 1.0000 - val_loss: 2.4672 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.60563\n",
      "Epoch 248/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.3455e-05 - accuracy: 1.0000 - val_loss: 2.4442 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.60563\n",
      "Epoch 249/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.2927e-05 - accuracy: 1.0000 - val_loss: 2.4416 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.60563\n",
      "Epoch 250/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3858e-04 - accuracy: 1.0000 - val_loss: 2.4424 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.60563\n",
      "Epoch 251/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.9891e-05 - accuracy: 1.0000 - val_loss: 2.4098 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.60563\n",
      "Epoch 252/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.1804e-04 - accuracy: 1.0000 - val_loss: 2.3893 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.60563\n",
      "Epoch 253/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2147e-04 - accuracy: 1.0000 - val_loss: 2.3792 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.60563\n",
      "Epoch 254/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0905e-05 - accuracy: 1.0000 - val_loss: 2.3911 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.60563\n",
      "Epoch 255/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5305e-05 - accuracy: 1.0000 - val_loss: 2.3857 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.60563\n",
      "Epoch 256/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.0142e-05 - accuracy: 1.0000 - val_loss: 2.3925 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.60563\n",
      "Epoch 257/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.9043e-05 - accuracy: 1.0000 - val_loss: 2.3981 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.60563\n",
      "Epoch 258/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 8.5534e-05 - accuracy: 1.0000 - val_loss: 2.3935 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.60563\n",
      "Epoch 259/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.1892e-05 - accuracy: 1.0000 - val_loss: 2.3852 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.60563\n",
      "Epoch 260/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.7576e-05 - accuracy: 1.0000 - val_loss: 2.3989 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.60563\n",
      "Epoch 261/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 6.9448e-05 - accuracy: 1.0000 - val_loss: 2.4088 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.60563\n",
      "Epoch 262/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.4681e-05 - accuracy: 1.0000 - val_loss: 2.3991 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.60563\n",
      "Epoch 263/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.5267e-05 - accuracy: 1.0000 - val_loss: 2.4025 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.60563\n",
      "Epoch 264/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.1563e-05 - accuracy: 1.0000 - val_loss: 2.3968 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.60563\n",
      "Epoch 265/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.7919e-05 - accuracy: 1.0000 - val_loss: 2.3774 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.60563\n",
      "Epoch 266/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.4394e-05 - accuracy: 1.0000 - val_loss: 2.3718 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.60563\n",
      "Epoch 267/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 4.3128e-05 - accuracy: 1.0000 - val_loss: 2.3809 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.60563\n",
      "Epoch 268/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.6293e-05 - accuracy: 1.0000 - val_loss: 2.3795 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.60563\n",
      "Epoch 269/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.9439e-05 - accuracy: 1.0000 - val_loss: 2.3918 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.60563\n",
      "Epoch 270/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.7614e-04 - accuracy: 1.0000 - val_loss: 2.3821 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.60563\n",
      "Epoch 271/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.4734e-05 - accuracy: 1.0000 - val_loss: 2.3664 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.60563\n",
      "Epoch 272/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2262e-04 - accuracy: 1.0000 - val_loss: 2.3807 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.60563\n",
      "Epoch 273/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.9425e-05 - accuracy: 1.0000 - val_loss: 2.3933 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.60563\n",
      "Epoch 274/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.5975e-05 - accuracy: 1.0000 - val_loss: 2.3959 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.60563\n",
      "Epoch 275/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0337 - accuracy: 0.9966 - val_loss: 3.3580 - val_accuracy: 0.5170\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.60563\n",
      "Epoch 276/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.2678e-04 - accuracy: 1.0000 - val_loss: 3.7941 - val_accuracy: 0.4218\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.60563\n",
      "Epoch 277/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3251e-04 - accuracy: 1.0000 - val_loss: 3.4724 - val_accuracy: 0.4626\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.60563\n",
      "Epoch 278/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.5177e-04 - accuracy: 1.0000 - val_loss: 3.0578 - val_accuracy: 0.5374\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.60563\n",
      "Epoch 279/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.8567e-04 - accuracy: 1.0000 - val_loss: 2.7470 - val_accuracy: 0.6327\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.60563\n",
      "Epoch 280/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.8100e-04 - accuracy: 1.0000 - val_loss: 2.5730 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.60563\n",
      "Epoch 281/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2197e-04 - accuracy: 1.0000 - val_loss: 2.4850 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.60563\n",
      "Epoch 282/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0871e-04 - accuracy: 1.0000 - val_loss: 2.4188 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.60563\n",
      "Epoch 283/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.6588e-05 - accuracy: 1.0000 - val_loss: 2.3722 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.60563\n",
      "Epoch 284/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.0209e-04 - accuracy: 1.0000 - val_loss: 2.3419 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.60563\n",
      "Epoch 285/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.9947e-04 - accuracy: 1.0000 - val_loss: 2.3310 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.60563\n",
      "Epoch 286/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0831e-04 - accuracy: 1.0000 - val_loss: 2.3069 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.60563\n",
      "Epoch 287/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 3.3759e-04 - accuracy: 1.0000 - val_loss: 2.2964 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.60563\n",
      "Epoch 288/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0015 - accuracy: 0.9983 - val_loss: 2.3847 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.60563\n",
      "Epoch 289/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 2.2710e-04 - accuracy: 1.0000 - val_loss: 2.3842 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.60563\n",
      "Epoch 290/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 5.1007e-05 - accuracy: 1.0000 - val_loss: 2.3081 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.60563\n",
      "Epoch 291/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2815e-04 - accuracy: 1.0000 - val_loss: 2.2944 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.60563\n",
      "Epoch 292/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.1654e-05 - accuracy: 1.0000 - val_loss: 2.2673 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.60563\n",
      "Epoch 293/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 7.3370e-05 - accuracy: 1.0000 - val_loss: 2.2621 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.60563\n",
      "Epoch 294/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3015e-04 - accuracy: 1.0000 - val_loss: 2.2337 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.60563\n",
      "Epoch 295/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.2086e-04 - accuracy: 1.0000 - val_loss: 2.2221 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.60563\n",
      "Epoch 296/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0818e-04 - accuracy: 1.0000 - val_loss: 2.2086 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.60563\n",
      "Epoch 297/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.4059e-04 - accuracy: 1.0000 - val_loss: 2.1993 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.60563\n",
      "Epoch 298/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 2.2258 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.60563\n",
      "Epoch 299/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.0841e-04 - accuracy: 1.0000 - val_loss: 1.9238 - val_accuracy: 0.7007\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.60563\n",
      "Epoch 300/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 1.3849e-04 - accuracy: 1.0000 - val_loss: 1.8825 - val_accuracy: 0.7007\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.60563\n",
      "predict test data\n",
      "183/183 [==============================] - 12s 68ms/step\n",
      "../npy/4\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "(732, 256, 256, 3)\n",
      "(732, 1)\n",
      "../npy/4\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(183, 256, 256, 3)\n",
      "(183, 1)\n",
      "(732, 1)\n",
      "(183, 1)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 2 0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, None, None, 2 0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, None, None, 2 0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, None, None, 5 0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, None, None, 5 0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, None, None, 5 0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, None, None, 5 0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, None, None, 1 0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, None, None, 1 0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, None, None, 1 0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, None, None, 1 0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, None, None, 1 0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, None, None, 1 0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, None, None, 2 0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, None, None, 2 0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            4098        global_average_pooling2d_5[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/300\n",
      "585/585 [==============================] - 25s 42ms/step - loss: 0.7362 - accuracy: 0.7009 - val_loss: 4.2521 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.25207, saving model to model_normalize_best(cv4).h5\n",
      "Epoch 2/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.3332 - accuracy: 0.8769 - val_loss: 0.9239 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.25207 to 0.92394, saving model to model_normalize_best(cv4).h5\n",
      "Epoch 3/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1182 - accuracy: 0.9641 - val_loss: 8.4400 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.92394\n",
      "Epoch 4/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0863 - accuracy: 0.9624 - val_loss: 5.8637 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.92394\n",
      "Epoch 5/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0987 - accuracy: 0.9658 - val_loss: 5.2583 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.92394\n",
      "Epoch 6/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0540 - accuracy: 0.9812 - val_loss: 6.5535 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.92394\n",
      "Epoch 7/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 7.1876 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.92394\n",
      "Epoch 8/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0367 - accuracy: 0.9932 - val_loss: 7.6226 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.92394\n",
      "Epoch 9/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 7.8076 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.92394\n",
      "Epoch 10/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0857 - accuracy: 0.9744 - val_loss: 5.0041 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.92394\n",
      "Epoch 11/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0837 - accuracy: 0.9692 - val_loss: 5.5053 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.92394\n",
      "Epoch 12/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0825 - accuracy: 0.9607 - val_loss: 6.4683 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.92394\n",
      "Epoch 13/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1046 - accuracy: 0.9641 - val_loss: 5.4154 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.92394\n",
      "Epoch 14/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.1072 - accuracy: 0.9658 - val_loss: 7.8728 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.92394\n",
      "Epoch 15/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0880 - accuracy: 0.9692 - val_loss: 8.3491 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.92394\n",
      "Epoch 16/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0579 - accuracy: 0.9795 - val_loss: 7.1570 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.92394\n",
      "Epoch 17/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0300 - accuracy: 0.9880 - val_loss: 6.6224 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.92394\n",
      "Epoch 18/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0212 - accuracy: 0.9966 - val_loss: 6.8013 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.92394\n",
      "Epoch 19/300\n",
      "585/585 [==============================] - 3s 6ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 6.3460 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.92394\n",
      "Epoch 20/300\n",
      "440/585 [=====================>........] - ETA: 0s - loss: 0.0078 - accuracy: 0.9977"
     ]
    }
   ],
   "source": [
    "def sch(epoch):\n",
    "    if epoch>100:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.0001\n",
    "    \n",
    "def get_nb_files(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    x = base_model.layers[-2].output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    #x = Dense(FC_SIZE, activation='relu')(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    model=multi_gpu_model(model,gpus=2)\n",
    "    model.compile(optimizer=SGD(lr=0.0001,decay=1e-6, momentum=0.9,nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def train():\n",
    "    for index in range(1,5):\n",
    "        mydata = dataProcess(256, 256)\n",
    "        X_train,y_train=mydata.load_train_data(index)\n",
    "        X_test,y_test=mydata.load_test_data(index)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        y_train=to_categorical(y_train,2)\n",
    "        y_test=to_categorical(y_test,2)\n",
    "\n",
    "        # setup model\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "        model = add_new_last_layer(base_model, 2)\n",
    "        model.summary()\n",
    "        #sc=LearningRateScheduler(sch)\n",
    "        for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        model=multi_gpu_model(model,gpus=2)\n",
    "        model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('model_normalize_best(cv%s).h5'%str(index), monitor='val_loss',mode='min', verbose=1, save_best_only=True,save_weights_only=False)\n",
    "        sc=LearningRateScheduler(sch)\n",
    "        model.fit(X_train, y_train, batch_size=40, epochs=300, verbose=1,validation_split=0.2, shuffle=True,callbacks=[model_checkpoint,sc])#1000\n",
    "\n",
    "        model.save(\"../result/model/model_normalize_last(cv%s).h5\"%str(index))\n",
    "\n",
    "        print('predict test data')\n",
    "        imgs_mask_test = model.predict(X_test, batch_size=1, verbose=1)\n",
    "        np.save('../result/npy/test_pred(cv%s).npy'%str(index), imgs_mask_test)\n",
    "       \n",
    "        \n",
    "#python classification.py --all_dir ../--nb_epoch 300 --batch_size 8\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_filename = '../../exp_CLAHE_test/result/model/model_normalize_last(cv0).h5'\n",
    "outer_keras_model = load_model(model_filename)\n",
    "outer_keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict test data\n",
      "936/936 [==============================] - 18s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "model.save(\"/home/ubuntu/gcubme4/Workspace/YJ_Kim/exp_CLAHE/code/model/model_normalize_last(cv%s).h5\"%str(0))\n",
    "\n",
    "print('predict test data')\n",
    "imgs_mask_test = model.predict(X_test, batch_size=1, verbose=1)\n",
    "np.save('/home/ubuntu/gcubme4/Workspace/YJ_Kim/exp_CLAHE/result/npy/test_pred(cv%s).npy'%str(0), imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../npy/0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(183, 256, 256, 3)\n",
      "(183, 1)\n",
      "183/183 [==============================] - 6s 30ms/step\n",
      "done\n",
      "cv_cnt ======================= 0\n",
      "precision =  0.7941176470588235\n",
      "recall =  0.5684210526315789\n",
      "f1score =  0.6625766871165645\n",
      "accuracy =  0.6994535519125683\n",
      "auc =  <function auc at 0x7f885fba00d0>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Feb 21 13:57:30 2018\n",
    "\n",
    "@author: gachon\n",
    "\"\"\"\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from data import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_curve,auc\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "cv_cnt=0\n",
    "\n",
    "#for cv_cnt in range(5):\n",
    "mydata = dataProcess(256, 256)\n",
    "X_test,y_test = mydata.load_test_data(cv_cnt)\n",
    "\n",
    "print('-'*30)\n",
    "print('load model...')\n",
    "print('-'*30)\n",
    "\n",
    "model = load_model('../result/model/model_normalize_last(cv%s).h5'%str(cv_cnt))\n",
    "y_pred = model.predict(X_test, batch_size=1, verbose=1)\n",
    "#np.save('../result/%s/npy/test_pred_epoch300(cv%s).npy'%(str(cv_cnt), str(cv_cnt)), y_pred)\n",
    "\n",
    "\n",
    "# f=open(\"../../exp_sharp/result_edit/%s/txt/result(cv%s).txt\"%(str(cv_cnt),str(cv_cnt)),\"w\")\n",
    "pred_label = []\n",
    "for i, v in enumerate(y_pred):\n",
    "\tpre_ans = v.argmax()\n",
    "\tpred_label.append(pre_ans)\n",
    "# \ttxt = str(y_test[i])+\",\"+str(pre_ans)+\",\"+str(v[0])+\",\"+str(v[1])+\"\\n\"\n",
    "# \tf.write(txt)\n",
    "# f.close()\n",
    "\n",
    "'''\n",
    "pred_label = []\n",
    "for i, v in enumerate(y_pred):\n",
    "\tpre_ans = v.argmax()\n",
    "\tpred_label.append(pre_ans)\n",
    "'''\n",
    "\n",
    "cm = confusion_matrix(y_test,pred_label)\n",
    "print(cm)\n",
    "acc = accuracy_score(y_test,pred_label)\n",
    "precision = precision_score(y_test,pred_label)\n",
    "f1score = f1_score(y_test,pred_label)\n",
    "recall = recall_score(y_test,pred_label)\n",
    "# #fp, tp, _ = roc_curve(y_test,pred_label)\n",
    "# fp, tp, _ = roc_curve(y_test,y_pred[:,1])\n",
    "# auc = auc(fp,tp)\n",
    "# fp_li = []\n",
    "# fp_li.append(fp)\n",
    "# print(fp_li)\n",
    "\n",
    "# with open(\"../result/fp_li(cv%s).txt\"%str(cv_cnt), \"w\") as output:\n",
    "#      for row in fp_li:\n",
    "#         output.write(str(row) + '\\n')\n",
    "print('done')\n",
    "print(\"cv_cnt =======================\",cv_cnt)\n",
    "print(\"precision = \",precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"f1score = \",f1score)\n",
    "print(\"accuracy = \",acc)\n",
    "# print(\"auc = \",auc)\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "# \tif y_test[i] == pred_label[i]:\n",
    "# \t\timg = array_to_img(X_test[i])\n",
    "# \t\timg.save(\"../../exp_HE/exp_edit2/result_edit/%s/img/true/%s_(T%s_P%s).jpg\"%(str(cv_cnt),i,y_test[i],pred_label[i]))\n",
    "# \telse:\n",
    "# \t\timg = array_to_img(X_test[i])\n",
    "# \t\timg.save(\"../../exp_HE/exp_edit2/result_edit/%s/img/false/%s_(T%s_P%s).jpg\"%(str(cv_cnt),i,y_test[i],pred_label[i]))\n",
    "        \n",
    "# sensitivity = []\n",
    "# specificity = []\n",
    "# acc = []\n",
    "# # dsc = []\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "#     mat = confusion_matrix(y_test,pred_label)\n",
    "#     if len(mat) == 2:\n",
    "#         ac = (mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "#         st = mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "#         sp = mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "#         if mat[1,0]+mat[1,1] == 0:\n",
    "#             specificity.append(sp)\n",
    "#             acc.append(ac)\n",
    "#         else:\n",
    "#             sensitivity.append(st)  \n",
    "#             specificity.append(sp)\n",
    "#             acc.append(ac)\n",
    "#     else:\n",
    "#         specificity.append(1)\n",
    "#         acc.append(1)\n",
    "\n",
    "# # for i in range(len(y_test)):\n",
    "# #     yt = y_test[i]\n",
    "# #     yp = pred_label[i]\n",
    "# #     if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "# #         dice = np.sum(yp[yt == 1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "# #         dsc.append(dice)\n",
    "\n",
    "# print(\"complete\")      \n",
    "# print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "# print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "# # print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "# # print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_list1 = np.load('../npy_edit/0/test_label1_256.npy') #test data mask\n",
    "# # true_list1 = true_list1.astype('float32')\n",
    "# # true_list1 = true_list1/255.0\n",
    "# # true_list1[true_list1 > 0.5] = 1\n",
    "# # true_list1[true_list1 <= 0.5] = 0\n",
    "# # print(true_list1.shape)\n",
    "\n",
    "# true_list2 = np.load('../npy_edit/0/test_label2_256.npy') #test data mask2\n",
    "\n",
    "# true_list = []\n",
    "# true_list = np.append(true_list1,true_list2)\n",
    "\n",
    "# true_list = true_list.astype('float32')\n",
    "# true_list = true_list/255.0\n",
    "# true_list[true_list > 0.5] = 1\n",
    "# true_list[true_list <= 0.5] = 0\n",
    "# print(true_list.shape)\n",
    "\n",
    "cv_cnt = 0\n",
    "\n",
    "mydata = dataProcess(256, 256)\n",
    "X_test, y_test = mydata.load_test_data(cv_cnt)\n",
    "\n",
    "pred_list = np.load('../result_edit/npy/test_pred(cv0).npy') #'/home/ubuntu/gcubme4/Workspace/HM_LEE/5th_data/pred/ap_exp1.npy')\n",
    "pred_list[pred_list > 0.5] = 1\n",
    "pred_list[pred_list <= 0.5] = 0\n",
    "# pred_list[pred_list > 127] = 1\n",
    "# pred_list[pred_list <= 127] = 0\n",
    "\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "acc = []\n",
    "dsc = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    yt = y_test[i].flatten()\n",
    "    yp = pred_list[i].flatten()\n",
    "    mat = confusion_matrix(yt,yp)\n",
    "    if len(mat) == 2:\n",
    "        ac = (mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "        st = mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "        sp = mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "        if mat[1,0]+mat[1,1] == 0:\n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "        else:\n",
    "            sensitivity.append(st)  \n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "    else:\n",
    "        specificity.append(1)\n",
    "        acc.append(1)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    yt = y_test[i]\n",
    "    yp = pred_list[i]\n",
    "    if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "        dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "        dsc.append(dice)\n",
    "\n",
    "print(\"complete\")      \n",
    "print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "\n",
    "# print(\"sensitivity min:\",np.min(sensitivity))\n",
    "# print(\"specificity min:\",np.min(specificity))\n",
    "# print(\"dsc min:\",np.min(dsc))\n",
    "# print(\"acc min:\",np.min(acc))\n",
    "\n",
    "# print(\"sensitivity max:\",np.max(sensitivity))\n",
    "# print(\"specificity max:\",np.max(specificity))\n",
    "# print(\"dsc max:\",np.max(dsc))\n",
    "# print(\"acc max:\",np.max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "\n",
    "keras.models.load_model(\"model_normalize_best(cv0).h5\")\n",
    "np.testing.assert_allclose(model.predict(test_input), reconstructed_model.predict(test_input))\n",
    "\n",
    "\n",
    "#loss,acc=model.evaluate(test_images,test_labels,verbose=2)\n",
    "#print(\"model_acc:{}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# origin\n",
    "\n",
    "\n",
    "def sch(epoch):\n",
    "    if epoch>100:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.0001\n",
    "    \n",
    "def get_nb_files(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    x = base_model.layers[-2].output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    #x = Dense(FC_SIZE, activation='relu')(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    multi_model=multi_gpu_model(model,gpus=2)\n",
    "    multi_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def train():\n",
    "    for index in range(0,5):\n",
    "        mydata = dataProcess(256, 256)\n",
    "        X_train,y_train=mydata.load_train_data(index)\n",
    "        X_test,y_test=mydata.load_test_data(index)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        y_train=to_categorical(y_train,2)\n",
    "        y_test=to_categorical(y_test,2)\n",
    "    \n",
    "        # setup model\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "        model = add_new_last_layer(base_model, 2)\n",
    "        #model.summary()\n",
    "        #sc=LearningRateScheduler(sch)\n",
    "        for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "            layer.trainable = True\n",
    "        multi_model=multi_gpu_model(model,gpus=2)\n",
    "        model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('model_normalize_best(cv%s).h5'%str(index), monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=False)\n",
    "        sc=LearningRateScheduler(sch)\n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=40, epochs=300, verbose=1,validation_split=0.2, shuffle=True,callbacks=[model_checkpoint,sc])#1000\n",
    "        print('predict test data')\n",
    "        #imgs_mask_test = model.predict(X_test, batch_size=1, verbose=1)\n",
    "        #np.save('../result/npy/test_pred_1024_nopreprocess.npy', imgs_mask_test)\n",
    "        model.save(\"model_normalize_last(cv%s).h5\"%str(index))\n",
    "        \n",
    "#python classification.py --all_dir ../--nb_epoch 300 --batch_size 8\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
